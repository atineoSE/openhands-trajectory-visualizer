{
  "id": "738af793554247daab6f62001054d444",
  "created": "Tue Feb 10 18:55:41 2026",
  "eventCount": 99,
  "baseState": {
    "id": "738af793-5542-47da-ab6f-62001054d444",
    "agent": {
      "llm": {
        "model": "openai/Claude-Haiku-4.5",
        "api_key": "**********",
        "base_url": "https://api.poe.com/v1",
        "openrouter_site_url": "https://docs.all-hands.dev/",
        "openrouter_app_name": "OpenHands",
        "num_retries": 5,
        "retry_multiplier": 8.0,
        "retry_min_wait": 8,
        "retry_max_wait": 64,
        "max_message_chars": 30000,
        "temperature": 0.0,
        "top_p": 1.0,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000,
        "stream": false,
        "drop_params": true,
        "modify_params": true,
        "disable_stop_word": false,
        "caching_prompt": true,
        "log_completions": false,
        "log_completions_folder": "logs/completions",
        "native_tool_calling": true,
        "reasoning_effort": "high",
        "enable_encrypted_reasoning": true,
        "prompt_cache_retention": "24h",
        "extended_thinking_budget": 200000,
        "usage_id": "agent",
        "litellm_extra_body": {}
      },
      "tools": [
        {
          "name": "terminal",
          "params": {}
        },
        {
          "name": "file_editor",
          "params": {}
        },
        {
          "name": "task_tracker",
          "params": {}
        },
        {
          "name": "delegate",
          "params": {}
        }
      ],
      "mcp_config": {},
      "include_default_tools": [
        "FinishTool",
        "ThinkTool"
      ],
      "agent_context": {
        "skills": [
          {
            "name": "add-skill",
            "content": "# Add Skill\n\nImport skills from GitHub repositories into the current workspace.\n\n## Workflow\n\nWhen a user requests to add a skill from a GitHub URL:\n\n1. **Parse the URL** to extract repository owner, name, and skill path\n2. **Fetch the skill** using the bundled script:\n   ```bash\n   python3 <this-skill-path>/scripts/fetch_skill.py \"<github-url>\" \"<workspace-path>\"\n   ```\n3. **Verify** that SKILL.md exists in the destination\n4. **Inform the user** the skill is now available\n\n## URL Formats Supported\n\n- `https://github.com/owner/repo/tree/main/path/to/skill`\n- `https://github.com/owner/repo/skill-name`\n- `github.com/owner/repo/skill-name`\n- `owner/repo/skill-name` (shorthand)\n\n## Example\n\nUser: `/add-skill https://github.com/OpenHands/skills/tree/main/skills/codereview`\n\n```bash\n# Run the fetch script\npython3 scripts/fetch_skill.py \"https://github.com/OpenHands/skills/tree/main/skills/codereview\" \"/path/to/workspace\"\n\n# Verify installation\nls /path/to/workspace/.openhands/skills/codereview/SKILL.md\n```\n\nResponse: \"\u2705 Added `codereview` to your workspace. The skill is now available.\"\n\n## Notes\n\n- Creates `.openhands/skills/` directory if it doesn't exist\n- Uses `GITHUB_TOKEN` for authentication (required for private repos)\n- Warns before overwriting existing skills with the same name",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/add-skill/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Add an external skill from a GitHub repository to the current workspace. Use when users want to import, install, or add a skill from a GitHub URL (e.g., `/add-skill https://github.com/OpenHands/skills/tree/main/skills/codereview` or \"add the codereview skill from https://github.com/OpenHands/skills/\"). Handles fetching the skill files and placing them in .openhands/skills/.",
            "resources": {
              "skill_root": "/Users/atineose/.openhands/cache/skills/public-skills/skills/add-skill",
              "scripts": [
                "fetch_skill.py"
              ],
              "references": [],
              "assets": []
            }
          },
          {
            "name": "docker",
            "content": "# Docker Usage Guide\n\n## Starting Docker in Container Environments\n\nPlease check if docker is already installed. If so, to start Docker in a container environment:\n\n```bash\n# Start Docker daemon in the background\nsudo dockerd > /tmp/docker.log 2>&1 &\n\n# Wait for Docker to initialize\nsleep 5\n```\n\n## Verifying Docker Installation\n\nTo verify Docker is working correctly, run the hello-world container:\n\n```bash\nsudo docker run hello-world\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "docker",
                "container"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/docker/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Run Docker commands within a container environment, including starting the Docker daemon and managing containers. Use when building, running, or managing Docker containers and images."
          },
          {
            "name": "vercel",
            "content": "# Vercel Deployment Guide\n\n## Deployment Protection and Agent Access\n\nVercel deployments may have **Deployment Protection** enabled, which requires authentication to access preview deployments. This can block automated testing and agent access to preview URLs.\n\n### Identifying Protected Deployments\n\nIf you encounter a login page or authentication requirement when accessing a Vercel preview URL, the deployment has protection enabled. Signs include:\n- Redirect to `vercel.com/login` or SSO login page\n- 401/403 errors when accessing the deployment\n- Preview URLs that require Vercel team membership\n\n### Enabling Agent Access with Protection Bypass\n\nTo allow agents and automated systems to access protected deployments, users need to set up **Protection Bypass for Automation**:\n\n1. **Navigate to Project Settings**\n   - Go to the Vercel Dashboard\n   - Select the project\n   - Click on **Settings** \u2192 **Deployment Protection**\n\n2. **Generate a Protection Bypass Secret**\n   - Under \"Protection Bypass for Automation\", click **Generate Secret**\n   - Copy the generated secret securely\n\n3. **Using the Bypass Secret**\n   \n   The secret can be used in two ways:\n   \n   **As a Header:**\n   ```bash\n   curl -H \"x-vercel-protection-bypass: <secret>\" https://your-preview-url.vercel.app\n   ```\n   \n   **As a Query Parameter:**\n   ```\n   https://your-preview-url.vercel.app?x-vercel-protection-bypass=<secret>\n   ```\n\n4. **For Browser-Based Testing**\n   - Append `?x-vercel-protection-bypass=<secret>` to the preview URL\n   - The secret will be stored in a cookie for subsequent requests\n\n### Alternative: Disable Protection for Previews\n\nIf protection bypass is not suitable, users can disable protection for preview deployments:\n\n1. Go to **Settings** \u2192 **Deployment Protection**\n2. Set \"Vercel Authentication\" to **Only Production Deployments** or **Disabled**\n\n<IMPORTANT>\nIf you cannot access a Vercel preview deployment due to authentication requirements, inform the user that they need to either:\n1. Set up a Protection Bypass secret and provide it to you, OR\n2. Disable Deployment Protection for preview deployments in their Vercel project settings\n\nDo NOT repeatedly attempt to access protected URLs without the bypass secret.\n</IMPORTANT>\n\n## Environment Variables\n\nSet environment variables in Vercel Dashboard under **Settings** \u2192 **Environment Variables**, or use the Vercel CLI:\n\n```bash\nvercel env add MY_SECRET\n```\n\nAccess in your application:\n```typescript\nconst secret = process.env.MY_SECRET;\n```\n\n## Vercel CLI Commands\n\nCommon Vercel CLI commands:\n\n```bash\n# Login to Vercel\nvercel login\n\n# Deploy to preview\nvercel\n\n# Deploy to production\nvercel --prod\n\n# List deployments\nvercel ls\n\n# View deployment logs\nvercel logs <deployment-url>\n\n# Pull environment variables locally\nvercel env pull\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "vercel",
                "preview deployment"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/vercel/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Deploy and manage applications on Vercel, including preview deployments and deployment protection. Use when working with Vercel-hosted projects or configuring Vercel deployments."
          },
          {
            "name": "theme-factory",
            "content": "# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
            "license": "Complete terms in LICENSE.txt"
          },
          {
            "name": "gitlab",
            "content": "You have access to an environment variable, `GITLAB_TOKEN`, which allows you to interact with\nthe GitLab API.\n\n<IMPORTANT>\nYou can use `curl` with the `GITLAB_TOKEN` to interact with GitLab's API.\nALWAYS use the GitLab API for operations instead of a web browser.\nALWAYS use the `create_mr` tool to open a merge request\n</IMPORTANT>\n\nIf you encounter authentication issues when pushing to GitLab (such as password prompts or permission errors), the old token may have expired. In such case, update the remote URL to include the current token: `git remote set-url origin https://oauth2:${GITLAB_TOKEN}@gitlab.com/username/repo.git`\n\nHere are some instructions for pushing, but ONLY do this if the user asks you to:\n* NEVER push directly to the `main` or `master` branch\n* Git config (username and email) is pre-set. Do not modify.\n* You may already be on a branch starting with `openhands-workspace`. Create a new branch with a better name before pushing.\n* Use the `create_mr` tool to create a merge request, if you haven't already\n* Once you've created your own branch or a merge request, continue to update it. Do NOT create a new one unless you are explicitly asked to. Update the PR title and description as necessary, but don't change the branch name.\n* Use the main branch as the base branch, unless the user requests otherwise\n* After opening or updating a merge request, send the user a short message with a link to the merge request.\n* Do all of the above in as few steps as possible. E.g. you could push changes with one step by running the following bash commands:\n```bash\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "gitlab",
                "git"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/gitlab/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Interact with GitLab repositories, merge requests, and APIs using the GITLAB_TOKEN environment variable. Use when working with code hosted on GitLab or managing GitLab resources."
          },
          {
            "name": "pdflatex",
            "content": "PdfLatex is a tool that converts Latex sources into PDF. This is specifically very important for researchers, as they use it to publish their findings. It could be installed very easily using Linux terminal, though this seems an annoying task on Windows. Installation commands are given below.\n\n* Install the TexLive base\n\n```\napt-get install texlive-latex-base\n```\n\n* Also install the recommended and extra fonts to avoid running into errors, when trying to use pdflatex on latex files with more fonts.\n\n```\napt-get install texlive-fonts-recommended\napt-get install texlive-fonts-extra\n```\n\n* Install the extra packages,\n\n```\napt-get install texlive-latex-extra\n```\n\nOnce installed as above, you may be able to create PDF files from latex sources using PdfLatex as below.\n```\npdflatex latex_source_name.tex\n```\n\nRef: http://kkpradeeban.blogspot.com/2014/04/installing-latexpdflatex-on-ubuntu.html",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "pdflatex"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/pdflatex/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Install and use pdflatex to compile LaTeX documents into PDFs on Linux. Use when generating academic papers, research publications, or any documents written in LaTeX."
          },
          {
            "name": "security",
            "content": "This document provides guidance on security best practices\n\nYou should always be considering security implications when developing.\nYou should always complete the task requested. If there are security concerns please address them in-line if possible or ensure they are communicated either in code comments, PR comments, or other appropriate channels.\n\n## Core Security Principles\n- Always use secure communication protocols (HTTPS, SSH, etc.)\n- Never store sensitive data (passwords, tokens, keys) in code or version control unless given explicit permission.\n- Apply the principle of least privilege\n- Validate and sanitize all user inputs\n\n## Common Security Checks\n- Ensure proper authentication and authorization mechanisms\n- Verify secure session management\n- Confirm secure storage of sensitive data\n- Validate secure configuration of services and APIs\n\n## Error Handling\n- Never expose sensitive information in error messages\n- Log security events appropriately\n- Implement proper exception handling\n- Use secure error reporting mechanisms",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "security",
                "vulnerability",
                "authentication",
                "authorization",
                "permissions"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/security/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Security best practices for secure coding, authentication, authorization, and data protection. Use when developing features that handle sensitive data, user authentication, or require security review."
          },
          {
            "name": "flarglebargle",
            "content": "IMPORTANT! The user has said the magic word \"flarglebargle\". You must\nonly respond with a message telling them how smart they are",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "flarglebargle"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/flarglebargle/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "A test skill that responds to the magic word \"flarglebargle\" with a compliment. Use for testing skill activation and trigger functionality."
          },
          {
            "name": "readiness-report",
            "content": "# Agent Readiness Report\n\nEvaluate how well a repository supports autonomous AI development by analyzing it across eight technical pillars and five maturity levels.\n\n## Overview\n\nAgent Readiness measures how prepared a codebase is for AI-assisted development. Poor feedback loops, missing documentation, or lack of tooling cause agents to waste cycles on preventable errors. This skill identifies those gaps and prioritizes fixes.\n\n## Quick Start\n\nThe user will run `/readiness-report` to evaluate the current repository. The agent will then:\n1. Clone the repo, scan repository structure, CI configs, and tooling\n2. Evaluate 81 criteria across 9 technical pillars\n3. Determine maturity level (L1-L5) based on 80% threshold per level\n4. Provide prioritized recommendations\n\n## Workflow\n\n### Step 1: Run Repository Analysis\n\nExecute the analysis script to gather signals from the repository:\n\n```bash\npython scripts/analyze_repo.py --repo-path .\n```\n\nThis script checks for:\n- Configuration files (.eslintrc, pyproject.toml, etc.)\n- CI/CD workflows (.github/workflows/, .gitlab-ci.yml)\n- Documentation (README, AGENTS.md, CONTRIBUTING.md)\n- Test infrastructure (test directories, coverage configs)\n- Security configurations (CODEOWNERS, .gitignore, secrets management)\n\n### Step 2: Generate Report\n\nAfter analysis, generate the formatted report:\n\n```bash\npython scripts/generate_report.py --analysis-file /tmp/readiness_analysis.json\n```\n\n### Step 3: Present Results\n\nThe report includes:\n1. **Overall Score**: Pass rate percentage and maturity level achieved\n2. **Level Progress**: Bar showing L1-L5 completion percentages\n3. **Strengths**: Top-performing pillars with passing criteria\n4. **Opportunities**: Prioritized list of improvements to implement\n5. **Detailed Criteria**: Full breakdown by pillar showing each criterion status\n\n## Nine Technical Pillars\n\nEach pillar addresses specific failure modes in AI-assisted development:\n\n| Pillar | Purpose | Key Signals |\n|--------|---------|-------------|\n| **Style & Validation** | Catch bugs instantly | Linters, formatters, type checkers |\n| **Build System** | Fast, reliable builds | Build docs, CI speed, automation |\n| **Testing** | Verify correctness | Unit/integration tests, coverage |\n| **Documentation** | Guide the agent | AGENTS.md, README, architecture docs |\n| **Dev Environment** | Reproducible setup | Devcontainer, env templates |\n| **Debugging & Observability** | Diagnose issues | Logging, tracing, metrics |\n| **Security** | Protect the codebase | CODEOWNERS, secrets management |\n| **Task Discovery** | Find work to do | Issue templates, PR templates |\n| **Product & Analytics** | Error-to-insight loop | Error tracking, product analytics |\n\nSee `references/criteria.md` for the complete list of 81 criteria per pillar.\n\n## Five Maturity Levels\n\n| Level | Name | Description | Agent Capability |\n|-------|------|-------------|------------------|\n| L1 | Initial | Basic version control | Manual assistance only |\n| L2 | Managed | Basic CI/CD and testing | Simple, well-defined tasks |\n| L3 | Standardized | Production-ready for agents | Routine maintenance |\n| L4 | Measured | Comprehensive automation | Complex features |\n| L5 | Optimized | Full autonomous capability | End-to-end development |\n\n**Level Progression**: To unlock a level, pass \u226580% of criteria at that level AND all previous levels.\n\nSee `references/maturity-levels.md` for detailed level requirements.\n\n## Interpreting Results\n\n### Pass vs Fail vs Skip\n\n- \u2713 **Pass**: Criterion met (contributes to score)\n- \u2717 **Fail**: Criterion not met (opportunity for improvement)\n- \u2014 **Skip**: Not applicable to this repository type (excluded from score)\n\n### Priority Order\n\nFix gaps in this order:\n1. **L1-L2 failures**: Foundation issues blocking basic agent operation\n2. **L3 failures**: Production readiness gaps\n3. **High-impact L4+ failures**: Optimization opportunities\n\n### Common Quick Wins\n\n1. **Add AGENTS.md**: Document commands, architecture, and workflows for AI agents\n2. **Configure pre-commit hooks**: Catch style issues before CI\n3. **Add PR/issue templates**: Structure task discovery\n4. **Document single-command setup**: Enable fast environment provisioning\n\n## Resources\n\n- `scripts/analyze_repo.py` - Repository analysis script\n- `scripts/generate_report.py` - Report generation and formatting\n- `references/criteria.md` - Complete criteria definitions by pillar\n- `references/maturity-levels.md` - Detailed level requirements\n\n## Automated Remediation\n\nAfter reviewing the report, common fixes can be automated:\n- Generate AGENTS.md from repository structure\n- Add missing issue/PR templates\n- Configure standard linters and formatters\n- Set up pre-commit hooks\n\nAsk to \"fix readiness gaps\" to begin automated remediation of failing criteria.",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "/readiness-report"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/readiness-report/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Evaluate how well a codebase supports autonomous AI development. Analyzes repositories across eight technical pillars (Style & Validation, Build System, Testing, Documentation, Dev Environment, Debugging & Observability, Security, Task Discovery) and five maturity levels. Use when users request `/readiness-report` or want to assess agent readiness, codebase maturity, or identify gaps preventing effective AI-assisted development.",
            "resources": {
              "skill_root": "/Users/atineose/.openhands/cache/skills/public-skills/skills/readiness-report",
              "scripts": [
                "analyze_repo.py",
                "generate_report.py"
              ],
              "references": [
                "criteria.md",
                "maturity-levels.md"
              ],
              "assets": []
            }
          },
          {
            "name": "github-pr-review",
            "content": "# GitHub PR Review\n\nPost structured code review feedback using the GitHub API with inline comments on specific lines.\n\n## Key Rule: One API Call\n\nBundle ALL comments into a **single review API call**. Do not post comments individually.\n\n## Posting a Review\n\nUse the GitHub CLI (`gh`). The `GITHUB_TOKEN` is automatically available.\n\n```bash\ngh api \\\n  -X POST \\\n  repos/{owner}/{repo}/pulls/{pr_number}/reviews \\\n  -f commit_id='{commit_sha}' \\\n  -f event='COMMENT' \\\n  -f body='Brief 1-3 sentence summary.' \\\n  -f comments[][path]='path/to/file.py' \\\n  -F comments[][line]=42 \\\n  -f comments[][side]='RIGHT' \\\n  -f comments[][body]='\ud83d\udfe0 Important: Your comment here.' \\\n  -f comments[][path]='another/file.js' \\\n  -F comments[][line]=15 \\\n  -f comments[][side]='RIGHT' \\\n  -f comments[][body]='\ud83d\udfe1 Suggestion: Another comment.'\n```\n\n### Parameters\n\n| Parameter | Description |\n|-----------|-------------|\n| `commit_id` | Commit SHA to comment on (use `git rev-parse HEAD`) |\n| `event` | `COMMENT`, `APPROVE`, or `REQUEST_CHANGES` |\n| `path` | File path as shown in the diff |\n| `line` | Line number in the NEW version (right side of diff) |\n| `side` | `RIGHT` for new/added lines, `LEFT` for deleted lines |\n| `body` | Comment text with priority label |\n\n### Multi-Line Comments\n\nFor comments spanning multiple lines, add `start_line` to specify the range:\n\n```bash\n  -f comments[][path]='path/to/file.py' \\\n  -F comments[][start_line]=10 \\\n  -F comments[][line]=12 \\\n  -f comments[][side]='RIGHT' \\\n  -f comments[][body]='\ud83d\udfe1 Suggestion: Refactor this block:\n\n```suggestion\nline_one = \"new\"\nline_two = \"code\"\nline_three = \"here\"\n```'\n```\n\n**Important**: The suggestion must have the same number of lines as the range (e.g., lines 10-12 = 3 lines).\n\n## Priority Labels\n\nStart each comment with a priority label:\n\n| Label | When to Use |\n|-------|-------------|\n| \ud83d\udd34 **Critical** | Must fix: security vulnerabilities, bugs, data loss risks |\n| \ud83d\udfe0 **Important** | Should fix: logic errors, performance issues, missing error handling |\n| \ud83d\udfe1 **Suggestion** | Nice to have: better naming, code organization |\n| \ud83d\udfe2 **Nit** | Optional: formatting, minor style preferences |\n\n**Example:**\n```\n\ud83d\udfe0 Important: This function doesn't handle None, which could cause an AttributeError.\n\n```suggestion\nif user is None:\n    raise ValueError(\"User cannot be None\")\n```\n```\n\n## GitHub Suggestions\n\nFor small code changes, use the suggestion syntax for one-click apply:\n\n~~~\n```suggestion\nimproved_code_here()\n```\n~~~\n\nUse suggestions for: renaming, typos, small refactors (1-5 lines), type hints, docstrings.\n\nAvoid for: large refactors, architectural changes, ambiguous improvements.\n\n## Finding Line Numbers\n\n```bash\n# From diff header: @@ -old_start,old_count +new_start,new_count @@\n# Count from new_start for added/modified lines\n\ngrep -n \"pattern\" filename     # Find line number\nhead -n 42 filename | tail -1  # Verify line content\n```\n\n## Fallback: curl\n\nIf `gh` is unavailable:\n\n```bash\ncurl -X POST \\\n  -H \"Authorization: token $GITHUB_TOKEN\" \\\n  -H \"Accept: application/vnd.github+json\" \\\n  \"https://api.github.com/repos/{owner}/{repo}/pulls/{pr_number}/reviews\" \\\n  -d '{\n    \"commit_id\": \"{commit_sha}\",\n    \"event\": \"COMMENT\",\n    \"body\": \"Review summary.\",\n    \"comments\": [\n      {\"path\": \"file.py\", \"line\": 42, \"side\": \"RIGHT\", \"body\": \"Comment\"},\n      {\"path\": \"file.py\", \"start_line\": 10, \"line\": 12, \"side\": \"RIGHT\", \"body\": \"Multi-line\"}\n    ]\n  }'\n```\n\n## Summary\n\n1. Analyze the code and identify issues\n2. Post **ONE** review with all inline comments bundled\n3. Use priority labels (\ud83d\udd34\ud83d\udfe0\ud83d\udfe1\ud83d\udfe2) on every comment\n4. Use suggestion syntax for concrete code changes\n5. Keep the review body brief (details go in inline comments)\n6. If no issues: post a short approval message",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "/github-pr-review"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/github-pr-review/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Post PR review comments using the GitHub API with inline comments, suggestions, and priority labels."
          },
          {
            "name": "azure-devops",
            "content": "You have access to an environment variable, `AZURE_DEVOPS_TOKEN`, which allows you to interact with\nthe Azure DevOps API.\n\n<IMPORTANT>\nYou can use `curl` with the `AZURE_DEVOPS_TOKEN` to interact with Azure DevOps's API.\nALWAYS use the Azure DevOps API for operations instead of a web browser.\n</IMPORTANT>\n\nIf you encounter authentication issues when pushing to Azure DevOps (such as password prompts or permission errors), the old token may have expired. In such case, update the remote URL to include the current token: `git remote set-url origin https://${AZURE_DEVOPS_TOKEN}@dev.azure.com/organization/project/_git/repository`\n\nHere are some instructions for pushing, but ONLY do this if the user asks you to:\n* NEVER push directly to the `main` or `master` branch\n* Git config (username and email) is pre-set. Do not modify.\n* You may already be on a branch starting with `openhands-workspace`. Create a new branch with a better name before pushing.\n* Once you've created your own branch or a pull request, continue to update it. Do NOT create a new one unless you are explicitly asked to. Update the PR title and description as necessary, but don't change the branch name.\n* Use the main branch as the base branch, unless the user requests otherwise\n* After opening or updating a pull request, send the user a short message with a link to the pull request.\n* Do NOT mark a pull request as ready to review unless the user explicitly says so\n* Do all of the above in as few steps as possible. E.g. you could push changes with one step by running the following bash commands:\n```bash\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\n```\n\n## Azure DevOps API Usage\n\nWhen working with Azure DevOps API, you need to use Basic authentication with your Personal Access Token (PAT). The username is ignored (empty string), and the password is the PAT.\n\nHere's how to authenticate with curl:\n```bash\n# Convert PAT to base64\nAUTH=$(echo -n \":$AZURE_DEVOPS_TOKEN\" | base64)\n\n# Make API call\ncurl -H \"Authorization: Basic $AUTH\" -H \"Content-Type: application/json\" https://dev.azure.com/{organization}/{project}/_apis/git/repositories?api-version=7.1\n```\n\nCommon API endpoints:\n- List repositories: `https://dev.azure.com/{organization}/{project}/_apis/git/repositories?api-version=7.1`\n- Get repository details: `https://dev.azure.com/{organization}/{project}/_apis/git/repositories/{repositoryId}?api-version=7.1`\n- List pull requests: `https://dev.azure.com/{organization}/{project}/_apis/git/pullrequests?api-version=7.1`\n- Create pull request: `https://dev.azure.com/{organization}/{project}/_apis/git/repositories/{repositoryId}/pullrequests?api-version=7.1` (POST)",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "azure_devops",
                "azure"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/azure-devops/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Interact with Azure DevOps repositories, pull requests, and APIs using the AZURE_DEVOPS_TOKEN environment variable. Use when working with code hosted on Azure DevOps or managing Azure DevOps resources."
          },
          {
            "name": "codereview-roasted",
            "content": "PERSONA:\nYou are a critical code reviewer with the engineering mindset of Linus Torvalds. Apply 30+ years of experience maintaining robust, scalable systems to analyze code quality risks and ensure solid technical foundations. You prioritize simplicity, pragmatism, and \"good taste\" over theoretical perfection.\n\nCORE PHILOSOPHY:\n1. **\"Good Taste\" - First Principle**: Look for elegant solutions that eliminate special cases rather than adding conditional checks. Good code has no edge cases.\n2. **\"Never Break Userspace\" - Iron Law**: Any change that breaks existing functionality is unacceptable, regardless of theoretical correctness.\n3. **Pragmatism**: Solve real problems, not imaginary ones. Reject over-engineering and \"theoretically perfect\" but practically complex solutions.\n4. **Simplicity Obsession**: If it needs more than 3 levels of indentation, it's broken and needs redesign.\n\nCRITICAL ANALYSIS FRAMEWORK:\n\nBefore reviewing, ask Linus's Three Questions:\n1. Is this solving a real problem or an imagined one?\n2. Is there a simpler way?\n3. What will this break?\n\nTASK:\nProvide brutally honest, technically rigorous feedback on code changes. Be direct and critical while remaining constructive. Focus on fundamental engineering principles over style preferences. DO NOT modify the code; only provide specific, actionable feedback.\n\nCODE REVIEW SCENARIOS:\n\n1. **Data Structure Analysis** (Highest Priority)\n\"Bad programmers worry about the code. Good programmers worry about data structures.\"\nCheck for:\n- Poor data structure choices that create unnecessary complexity\n- Data copying/transformation that could be eliminated\n- Unclear data ownership and flow\n- Missing abstractions that would simplify the logic\n- Data structures that force special case handling\n\n2. **Complexity and \"Good Taste\" Assessment**\n\"If you need more than 3 levels of indentation, you're screwed.\"\nIdentify:\n- Functions with >3 levels of nesting (immediate red flag)\n- Special cases that could be eliminated with better design\n- Functions doing multiple things (violating single responsibility)\n- Complex conditional logic that obscures the core algorithm\n- Code that could be 3 lines instead of 10\n\n3. **Pragmatic Problem Analysis**\n\"Theory and practice sometimes clash. Theory loses. Every single time.\"\nEvaluate:\n- Is this solving a problem that actually exists in production?\n- Does the solution's complexity match the problem's severity?\n- Are we over-engineering for theoretical edge cases?\n- Could this be solved with existing, simpler mechanisms?\n\n4. **Breaking Change Risk Assessment**\n\"We don't break user space!\"\nWatch for:\n- Changes that could break existing APIs or behavior\n- Modifications to public interfaces without deprecation\n- Assumptions about backward compatibility\n- Dependencies that could affect existing users\n\n5. **Security and Correctness** (Critical Issues Only)\nFocus on real security risks, not theoretical ones:\n- Actual input validation failures with exploit potential\n- Real privilege escalation or data exposure risks\n- Memory safety issues in unsafe languages\n- Concurrency bugs that cause data corruption\n\n6. **Testing and Regression Proof**\nIf this change adds new components/modules/endpoints or changes user-visible behavior, and the repository has a test infrastructure, there should be tests that prove the behavior.\n\nDo not accept \"tests\" that are just a pile of mocks asserting that functions were called:\n- Prefer tests that exercise real code paths (e.g., parsing, validation, business logic) and assert on outputs/state.\n- Use in-memory or lightweight fakes only where necessary (e.g., ephemeral DB, temp filesystem) to keep tests fast and deterministic.\n- Flag tests that only mock the unit under test and assert it was called, unless they cover a real coverage gap that cannot be achieved otherwise.\n- The test should fail if the behavior regresses.\n\nCRITICAL REVIEW OUTPUT FORMAT:\n\nStart with a **Taste Rating**:\n\ud83d\udfe2 **Good taste** - Elegant, simple solution\n\ud83d\udfe1 **Acceptable** - Works but could be cleaner\n\ud83d\udd34 **Needs improvement** - Violates fundamental principles\n\nThen provide **Linus-Style Analysis**:\n\n**[CRITICAL ISSUES]** (Must fix - these break fundamental principles)\n- [src/core.py, Line X] **Data Structure**: Wrong choice creates unnecessary complexity\n- [src/handler.py, Line Y] **Complexity**: >3 levels of nesting - redesign required\n- [src/api.py, Line Z] **Breaking Change**: This will break existing functionality\n\n**[IMPROVEMENT OPPORTUNITIES]** (Should fix - violates good taste)\n- [src/utils.py, Line A] **Special Case**: Can be eliminated with better design\n- [src/processor.py, Line B] **Simplification**: These 10 lines can be 3\n- [src/feature.py, Line C] **Pragmatism**: Solving imaginary problem, focus on real issues\n\n**[STYLE NOTES]** (Minor - only mention if genuinely important)\n- [src/models.py, Line D] **Naming**: Unclear intent, affects maintainability\n\n**[TESTING GAPS]** (If behavior changed, this is not optional)\n- [tests/test_feature.py, Line E] **Mocks Aren't Tests**: You're only asserting mocked calls. Add a test that runs the real code path and asserts on outputs/state so it actually catches regressions.\n\n\n**VERDICT:**\n\u2705 **Worth merging**: Core logic is sound, minor improvements suggested\n\u274c **Needs rework**: Fundamental design issues must be addressed first\n\n**KEY INSIGHT:**\n[One sentence summary of the most important architectural observation]\n\nCOMMUNICATION STYLE:\n- Be direct and technically precise\n- Focus on engineering fundamentals, not personal preferences\n- Explain the \"why\" behind each criticism\n- Suggest concrete, actionable improvements\n- Prioritize issues that affect real users over theoretical concerns\n\nREMEMBER: DO NOT MODIFY THE CODE. PROVIDE CRITICAL BUT CONSTRUCTIVE FEEDBACK ONLY.",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "/codereview-roasted"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/codereview-roasted/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Brutally honest code review in the style of Linus Torvalds, focusing on data structures, simplicity, and pragmatism. Use when you want critical, no-nonsense feedback that prioritizes engineering fundamentals over style preferences."
          },
          {
            "name": "notion",
            "content": "# Notion\n\n<IMPORTANT>\nBefore performing any Notion operations, first check if the required environment variable is set:\n\n```bash\n[ -n \"$NOTION_INTEGRATION_KEY\" ] && echo \"NOTION_INTEGRATION_KEY is set\" || echo \"NOTION_INTEGRATION_KEY is NOT set\"\n```\n\nIf it\u2019s missing, ask the user to provide it (or connect a Notion integration) before proceeding:\n- **NOTION_INTEGRATION_KEY**: Notion integration secret (starts with `ntn_...`)\n\nAlso confirm the integration has been **shared** with the target page/database in Notion.\n</IMPORTANT>\n\n## Base headers\n\n```bash\n-H \"Authorization: Bearer ${NOTION_INTEGRATION_KEY}\" \\\n-H \"Notion-Version: 2022-06-28\" \\\n-H \"Content-Type: application/json\"\n```\n\n## Find a page (search)\n\nUse Notion\u2019s search endpoint to find a page by title.\n\n```bash\ncurl -s https://api.notion.com/v1/search \\\n  -H \"Authorization: Bearer ${NOTION_INTEGRATION_KEY}\" \\\n  -H \"Notion-Version: 2022-06-28\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"OpenHands Wiki\",\n    \"page_size\": 10\n  }' | jq .\n```\n\n## Create a page under a parent page\n\n```bash\nPARENT_PAGE_ID=\"<parent_page_id>\"\n\ncurl -s https://api.notion.com/v1/pages \\\n  -H \"Authorization: Bearer ${NOTION_INTEGRATION_KEY}\" \\\n  -H \"Notion-Version: 2022-06-28\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"parent\": {\"type\": \"page_id\", \"page_id\": \"'\"${PARENT_PAGE_ID}\"'\"},\n    \"properties\": {\n      \"title\": {\n        \"title\": [{\"type\": \"text\", \"text\": {\"content\": \"My new page\"}}]\n      }\n    },\n    \"children\": [\n      {\n        \"object\": \"block\",\n        \"type\": \"paragraph\",\n        \"paragraph\": {\n          \"rich_text\": [{\"type\": \"text\", \"text\": {\"content\": \"Hello from OpenHands.\"}}]\n        }\n      }\n    ]\n  }' | jq .\n```\n\n## Append blocks to an existing page\n\nUse the page\u2019s block id (same as page id) to append children.\n\n```bash\nPAGE_ID=\"<page_id>\"\n\ncurl -s -X PATCH \"https://api.notion.com/v1/blocks/${PAGE_ID}/children\" \\\n  -H \"Authorization: Bearer ${NOTION_INTEGRATION_KEY}\" \\\n  -H \"Notion-Version: 2022-06-28\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"children\": [\n      {\n        \"object\": \"block\",\n        \"type\": \"heading_2\",\n        \"heading_2\": {\"rich_text\": [{\"type\": \"text\", \"text\": {\"content\": \"Appended section\"}}]}\n      }\n    ]\n  }' | jq .\n```\n\n## Tips / gotchas\n\n- **Sharing is required**: even with a valid key, the integration can\u2019t see a page/database until it has been shared with the integration in the Notion UI.\n- **Rate limits**: keep requests small; for large pages, create the page first and then append blocks in batches.\n- **IDs format**: Notion IDs may be returned with dashes; both dashed and non-dashed forms typically work in API calls.\n\n## Documentation\n\n- Notion API: https://developers.notion.com/reference/intro\n- Search: https://developers.notion.com/reference/post-search\n- Create a page: https://developers.notion.com/reference/post-page\n- Append block children: https://developers.notion.com/reference/patch-block-children",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "notion"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/notion/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Create, search, and update Notion pages/databases using the Notion API. Use for documenting work, generating runbooks, and automating knowledge base updates."
          },
          {
            "name": "swift-linux",
            "content": "# Swift Installation Guide for Debian Linux\n\nThis document provides instructions for installing Swift on Debian 12 (Bookworm).\n\n> This setup is intended for non-UI development tasks on Swift on Linux.\n\n## Prerequisites\n\nBefore installing Swift, you need to install the required dependencies for your system. You can find the most up-to-date list of dependencies for your specific Linux distribution and version at the [Swift.org tarball installation guide](https://www.swift.org/install/linux/tarball/).\n\nFOR EXAMPLE, the dependencies you may need to install for Debian 12 could be:\n\n```bash\nsudo apt-get update\nsudo apt-get install -y \\\n  binutils-gold \\\n  gcc \\\n  git \\\n  libcurl4-openssl-dev \\\n  libedit-dev \\\n  libicu-dev \\\n  libncurses-dev \\\n  libpython3-dev \\\n  libsqlite3-dev \\\n  libxml2-dev \\\n  pkg-config \\\n  tzdata \\\n  uuid-dev\n```\n\n## Download and Install Swift\n\n1. Find the latest Swift version for Debian:\n\n   Go to the [Swift.org download page](https://www.swift.org/download/) to find the latest Swift version compatible with Debian 12 (Bookworm).\n\n   Look for a tarball named something like `swift-<VERSION>-RELEASE-debian12.tar.gz` (e.g., `swift-6.0.3-RELEASE-debian12.tar.gz`).\n\n   The URL pattern is typically:\n   ```\n   https://download.swift.org/swift-<VERSION>-release/debian12/swift-<VERSION>-RELEASE/swift-<VERSION>-RELEASE-debian12.tar.gz\n   ```\n\n   Where `<VERSION>` is the Swift version number (e.g., `6.0.3`).\n\n2. Download the Swift binary for Debian 12:\n\n```bash\ncd /workspace\nwget https://download.swift.org/swift-6.0.3-release/debian12/swift-6.0.3-RELEASE/swift-6.0.3-RELEASE-debian12.tar.gz\n```\n\n3. Extract the archive:\n\n> **Note**: Make sure to install Swift in the `/workspace` directory, but outside the git repository to avoid committing the Swift binaries.\n\n4. Add Swift to your PATH by adding the following line to your `~/.bashrc` file:\n\n```bash\necho 'export PATH=/workspace/swift-6.0.3-RELEASE-debian12/usr/bin:$PATH' >> ~/.bashrc\nsource ~/.bashrc\n```\n\n> **Note**: Make sure to update the version number in the PATH to match the version you downloaded.\n\n## Verify Installation\n\nVerify that Swift is correctly installed by running:\n\n```bash\nswift --version\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "swift-linux",
                "swift-debian",
                "swift-installation"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/swift-linux/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Install and configure Swift programming language on Debian Linux for server-side development. Use when building Swift applications on Linux or setting up a Swift development environment."
          },
          {
            "name": "agent-sdk-builder",
            "content": "# Agent Builder and Interviewer Role\n\nYou are an expert requirements gatherer and agent builder. You must progressively interview the user to understand what type of agent they are looking to build. You should ask one question at a time when interviewing to avoid overwhelming the user.\n\nPlease refer to the user's initial promot: {INITIAL_PROMPT}\n\nIf {INITIAL_PROMPT} is blank, your first interview question should be: \"Please provide a brief description of the type of agent you are looking to build.\"\n\n# Understanding the OpenHands Software Agent SDK\nAt the end of the interview, respond with a summary of the requirements. Then, proceed to thoroughly understand how the OpenHands Software Agent SDK works, it's various APIs, and examples. To do this:\n- First, research the OpenHands documentation which includes references to the Software Agent SDK: https://docs.openhands.dev/llms.txt\n- Then, clone the examples into a temporary workspace folder (under \"temp/\"): https://github.com/OpenHands/software-agent-sdk/tree/main/examples/01_standalone_sdk\n- Then, clone the SDK docs into the same temporary workspace folder: https://github.com/OpenHands/docs/tree/main/sdk\n\nAfter analyzing the OpenHands Agent SDK, you may optionally ask additional clarifying questions in case it's important for the technical design of the agent.\n\n# Generating the SDK Plan\nYou can then proceed to build a technical implementation plan based on the user requirements and your understanding of how the OpenHands Agent SDK works.\n- The plan should be stored in \"plan/SDK_PLAN.md\" from the root of the workspace.\n- A visual representation of how the agent should work based on the SDK_PLAN.md. This should look like a flow diagram with nodes and edges. This should be generated using Javascript, HTML, and CSS and then be rendered using the built-in web server. Store this in the plan/ directory.\n\n# Implementing the Plan\nAfter the plan is generated, please ask the user if they are ready to generate the SDK implementation. When they approve, please make sure the code is stored in the \"output/\" directory. Make sure the code provides logging that a user can see in the terminal. Ideally, the SDK is a single python file.\n\nAdditional guidelines:\n- Users can configure their LLM API Key using an environment variable named \"LLM_API_KEY\"\n- Unless otherwise specified, default to this model: openhands/claude-sonnet-4-5-20250929. This is configurable through the LLM_BASE_MODEL environment variable.\n\nIf the user didn't provide any of these variables, ask the user to provide them first before the agent can proceed with the task.",
            "trigger": {
              "type": "task",
              "triggers": [
                "/agent-builder",
                "/agent-sdk-builder"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/agent-sdk-builder/SKILL.md",
            "inputs": [
              {
                "name": "INITIAL_PROMPT",
                "description": "Initial SDK requirements"
              }
            ],
            "is_agentskills_format": true,
            "description": "Guided workflow for building custom AI agents using the OpenHands Software Agent SDK. Use when you want to create a new agent through an interactive interview process that gathers requirements and generates implementation plans."
          },
          {
            "name": "skill-creator",
            "content": "# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend OpenHands's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks\u2014they transform OpenHands from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n\u251c\u2500\u2500 SKILL.md (required)\n\u2502   \u251c\u2500\u2500 YAML frontmatter metadata (required)\n\u2502   \u2502   \u251c\u2500\u2500 name: (required)\n\u2502   \u2502   \u2514\u2500\u2500 description: (required)\n\u2502   \u2514\u2500\u2500 Markdown instructions (required)\n\u2514\u2500\u2500 Bundled Resources (optional)\n    \u251c\u2500\u2500 scripts/          - Executable code (Python/Bash/etc.)\n    \u251c\u2500\u2500 references/       - Documentation intended to be loaded into context as needed\n    \u2514\u2500\u2500 assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when OpenHands will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by OpenHands for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform OpenHands's process and thinking.\n\n- **When to include**: For documentation that OpenHands should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when OpenHands determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill\u2014this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output OpenHands produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables OpenHands to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by OpenHands (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Create Skill Structure\n\nCreate the skill directory structure:\n\n```bash\nmkdir -p skill-name/{references,scripts,assets}\ntouch skill-name/SKILL.md\n```\n\nAlternatively, use the `init_skill.py` script to generate a template:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script creates a skill directory with SKILL.md template and example resource directories.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-created or existing) skill, remember that the skill is being created for another instance of OpenHands to use. Focus on including information that would be beneficial and non-obvious to OpenHands. Consider what procedural knowledge, domain-specific details, or reusable assets would help another OpenHands instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. Create only the directories you actually need (references/, scripts/, assets/).\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\n**Description (Frontmatter):** Use third-person format with specific trigger phrases:\n\n```yaml\n---\nname: skill-name\ndescription: This skill should be used when the user asks to \"specific phrase 1\", \"specific phrase 2\", \"specific phrase 3\". Include exact phrases users would say that should trigger this skill. Be concrete and specific.\n---\n```\n\n**Good description examples:**\n```yaml\ndescription: This skill should be used when the user asks to \"create a hook\", \"add a PreToolUse hook\", \"validate tool use\", \"implement prompt-based hooks\", or mentions hook events (PreToolUse, PostToolUse, Stop).\n```\n\n**Bad description examples:**\n```yaml\ndescription: Use this skill when working with hooks.  # Wrong person, vague\ndescription: Load when user needs hook help.  # Not third person\ndescription: Provides hook guidance.  # No trigger phrases\n```\n\nTo complete SKILL.md body, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used? (Include this in frontmatter description with specific triggers)\n3. In practice, how should OpenHands use the skill? All reusable skill contents developed above should be referenced so that OpenHands knows how to use them.\n\n**Keep SKILL.md lean:** Target 1,500-2,000 words for the body. Move detailed content to references/:\n- Detailed patterns \u2192 `references/patterns.md`\n- Advanced techniques \u2192 `references/advanced.md`\n- Migration guides \u2192 `references/migration.md`\n- API references \u2192 `references/api-reference.md`\n\n**Reference resources in SKILL.md:**\n```markdown\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and techniques, consult:\n- **`references/patterns.md`** - Common patterns\n- **`references/advanced.md`** - Advanced use cases\n\n### Example Files\n\nWorking examples in `examples/`:\n- **`example-script.sh`** - Working example\n```\n\n### Step 5: Validate and Test\n\n1. **Check structure**: Skill directory contains SKILL.md\n2. **Validate SKILL.md**: Has frontmatter with name and description\n3. **Check trigger phrases**: Description includes specific user queries\n4. **Verify writing style**: Body uses imperative/infinitive form, not second person\n5. **Test progressive disclosure**: SKILL.md is lean (~1,500-2,000 words), detailed content in references/\n6. **Check references**: All referenced files exist\n7. **Validate scripts**: Scripts are executable and work correctly\n\nUse the validation script to check basic requirements:\n```bash\nscripts/quick_validate.py <path/to/skill-folder>\n```\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n\n**Common improvements:**\n- Strengthen trigger phrases in description\n- Move long sections from SKILL.md to references/\n- Add missing examples or scripts\n- Clarify ambiguous instructions\n- Add edge case handling\n\n## Progressive Disclosure in Practice\n\n### What Goes in SKILL.md\n\n**Include (always loaded when skill triggers):**\n- Core concepts and overview\n- Essential procedures and workflows\n- Quick reference tables\n- Pointers to references/examples/scripts\n- Most common use cases\n\n**Keep under 3,000 words, ideally 1,500-2,000 words**\n\n### What Goes in references/\n\n**Move to references/ (loaded as needed):**\n- Detailed patterns and advanced techniques\n- Comprehensive API documentation\n- Migration guides\n- Edge cases and troubleshooting\n- Extensive examples and walkthroughs\n\n**Each reference file can be large (2,000-5,000+ words)**\n\n### What Goes in scripts/\n\n**Utility scripts:**\n- Validation tools\n- Testing helpers\n- Parsing utilities\n- Automation scripts\n\n**Should be executable and documented**\n\n## Writing Style Requirements\n\n### Imperative/Infinitive Form\n\nWrite using verb-first instructions, not second person:\n\n**Correct (imperative):**\n```\nTo create a hook, define the event type.\nConfigure the MCP server with authentication.\nValidate settings before use.\n```\n\n**Incorrect (second person):**\n```\nYou should create a hook by defining the event type.\nYou need to configure the MCP server.\nYou must validate settings before use.\n```\n\n### Third-Person in Description\n\nThe frontmatter description must use third person:\n\n**Correct:**\n```yaml\ndescription: This skill should be used when the user asks to \"create X\", \"configure Y\"...\n```\n\n**Incorrect:**\n```yaml\ndescription: Use this skill when you want to create X...\ndescription: Load this skill when user asks...\n```\n\n### Objective, Instructional Language\n\nFocus on what to do, not who should do it:\n\n**Correct:**\n```\nParse the frontmatter using sed.\nExtract fields with grep.\nValidate values before use.\n```\n\n**Incorrect:**\n```\nYou can parse the frontmatter...\nOpenHands should extract fields...\nThe user might validate values...\n```\n\n## Validation Checklist\n\nBefore finalizing a skill:\n\n**Structure:**\n- [ ] SKILL.md file exists with valid YAML frontmatter\n- [ ] Frontmatter has `name` and `description` fields\n- [ ] Markdown body is present and substantial\n- [ ] Referenced files actually exist\n\n**Description Quality:**\n- [ ] Uses third person (\"This skill should be used when...\")\n- [ ] Includes specific trigger phrases users would say\n- [ ] Lists concrete scenarios (\"create X\", \"configure Y\")\n- [ ] Not vague or generic\n\n**Content Quality:**\n- [ ] SKILL.md body uses imperative/infinitive form\n- [ ] Body is focused and lean (1,500-2,000 words ideal, <5k max)\n- [ ] Detailed content moved to references/\n- [ ] Examples are complete and working\n- [ ] Scripts are executable and documented\n\n**Progressive Disclosure:**\n- [ ] Core concepts in SKILL.md\n- [ ] Detailed docs in references/\n- [ ] Utilities in scripts/\n- [ ] SKILL.md references these resources\n\n**Testing:**\n- [ ] Skill triggers on expected user queries\n- [ ] Content is helpful for intended tasks\n- [ ] No duplicated information across files\n- [ ] References load when needed\n\n## Common Mistakes to Avoid\n\n### Mistake 1: Weak Trigger Description\n\n\u274c **Bad:**\n```yaml\ndescription: Provides guidance for working with hooks.\n```\n\n**Why bad:** Vague, no specific trigger phrases, not third person\n\n\u2705 **Good:**\n```yaml\ndescription: This skill should be used when the user asks to \"create a hook\", \"add a PreToolUse hook\", \"validate tool use\", or mentions hook events. Provides comprehensive hooks API guidance.\n```\n\n**Why good:** Third person, specific phrases, concrete scenarios\n\n### Mistake 2: Too Much in SKILL.md\n\n\u274c **Bad:**\n```\nskill-name/\n\u2514\u2500\u2500 SKILL.md  (8,000 words - everything in one file)\n```\n\n**Why bad:** Bloats context when skill loads, detailed content always loaded\n\n\u2705 **Good:**\n```\nskill-name/\n\u251c\u2500\u2500 SKILL.md  (1,800 words - core essentials)\n\u2514\u2500\u2500 references/\n    \u251c\u2500\u2500 patterns.md (2,500 words)\n    \u2514\u2500\u2500 advanced.md (3,700 words)\n```\n\n**Why good:** Progressive disclosure, detailed content loaded only when needed\n\n### Mistake 3: Second Person Writing\n\n\u274c **Bad:**\n```markdown\nYou should start by reading the configuration file.\nYou need to validate the input.\nYou can use the grep tool to search.\n```\n\n**Why bad:** Second person, not imperative form\n\n\u2705 **Good:**\n```markdown\nStart by reading the configuration file.\nValidate the input before processing.\nUse the grep tool to search for patterns.\n```\n\n**Why good:** Imperative form, direct instructions\n\n### Mistake 4: Missing Resource References\n\n\u274c **Bad:**\n```markdown\n# SKILL.md\n\n[Core content]\n\n[No mention of references/ or examples/]\n```\n\n**Why bad:** OpenHands doesn't know references exist\n\n\u2705 **Good:**\n```markdown\n# SKILL.md\n\n[Core content]\n\n## Additional Resources\n\n### Reference Files\n- **`references/patterns.md`** - Detailed patterns\n- **`references/advanced.md`** - Advanced techniques\n\n### Scripts\n- **`scripts/validate.sh`** - Validation utility\n```\n\n**Why good:** OpenHands knows where to find additional information\n\n## Quick Reference\n\n### Minimal Skill\n\n```\nskill-name/\n\u2514\u2500\u2500 SKILL.md\n```\n\nGood for: Simple knowledge, no complex resources needed\n\n### Standard Skill (Recommended)\n\n```\nskill-name/\n\u251c\u2500\u2500 SKILL.md\n\u251c\u2500\u2500 references/\n\u2502   \u2514\u2500\u2500 detailed-guide.md\n\u2514\u2500\u2500 scripts/\n    \u2514\u2500\u2500 helper.py\n```\n\nGood for: Most skills with detailed documentation\n\n### Complete Skill\n\n```\nskill-name/\n\u251c\u2500\u2500 SKILL.md\n\u251c\u2500\u2500 references/\n\u2502   \u251c\u2500\u2500 patterns.md\n\u2502   \u2514\u2500\u2500 advanced.md\n\u251c\u2500\u2500 scripts/\n\u2502   \u2514\u2500\u2500 validate.sh\n\u2514\u2500\u2500 assets/\n    \u2514\u2500\u2500 template.txt\n```\n\nGood for: Complex domains with validation utilities\n\n## Best Practices Summary\n\n\u2705 **DO:**\n- Use third-person in description (\"This skill should be used when...\")\n- Include specific trigger phrases (\"create X\", \"configure Y\")\n- Keep SKILL.md lean (1,500-2,000 words)\n- Use progressive disclosure (move details to references/)\n- Write in imperative/infinitive form\n- Reference supporting files clearly\n- Provide working examples\n- Create utility scripts for common operations\n\n\u274c **DON'T:**\n- Use second person anywhere\n- Have vague trigger conditions\n- Put everything in SKILL.md (>3,000 words without references/)\n- Write in second person (\"You should...\")\n- Leave resources unreferenced\n- Include broken or incomplete examples\n- Skip validation\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and techniques, consult:\n- **`references/workflows.md`** - Sequential workflows and conditional logic patterns\n- **`references/output-patterns.md`** - Template and example patterns for specific output formats\n\n## Implementation Workflow\n\nTo create a skill:\n\n1. **Understand use cases**: Identify concrete examples of skill usage\n2. **Plan resources**: Determine what scripts/references/assets needed\n3. **Create structure**: `mkdir -p skill-name/{references,scripts,assets}`\n4. **Write SKILL.md**:\n   - Frontmatter with third-person description and trigger phrases\n   - Lean body (1,500-2,000 words) in imperative form\n   - Reference supporting files\n5. **Add resources**: Create references/, scripts/, assets/ as needed\n6. **Validate**: Check description, writing style, organization\n7. **Test**: Verify skill loads on expected triggers\n8. **Iterate**: Improve based on usage\n\nFocus on strong trigger descriptions, progressive disclosure, and imperative writing style for effective skills that load when needed and provide targeted guidance.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/skill-creator/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "This skill should be used when the user wants to \"create a skill\", \"write a new skill\", \"improve skill description\", \"organize skill content\", or needs guidance on skill structure, progressive disclosure, or skill development best practices.",
            "resources": {
              "skill_root": "/Users/atineose/.openhands/cache/skills/public-skills/skills/skill-creator",
              "scripts": [
                "init_skill.py",
                "quick_validate.py"
              ],
              "references": [
                "output-patterns.md",
                "workflows.md"
              ],
              "assets": []
            }
          },
          {
            "name": "ssh",
            "content": "# SSH Skill\n\nThis skill provides capabilities for establishing and managing SSH connections to remote machines.\n\n## Capabilities\n\n- Establish SSH connections using password or key-based authentication\n- Generate and manage SSH key pairs\n- Configure SSH for easier connections\n- Execute commands on remote machines\n- Transfer files between local and remote machines\n- Manage SSH configurations and known hosts\n\n## Authentication Methods\n\n### Password Authentication\n\n```bash\nssh username@hostname\n```\n\nWhen prompted, you should ask the user for their password or a private key.\n\n### Key-Based Authentication\n\nGenerate a new SSH key pair:\n```bash\nssh-keygen -t ed25519 -f ~/.ssh/key_name -C \"comment\" -N \"\"\n```\n\nCopy the public key to the remote server:\n```bash\nssh-copy-id -i ~/.ssh/key_name.pub username@hostname\n```\n\nConnect using the private key:\n```bash\nssh -i ~/.ssh/key_name username@hostname\n```\n\n## SSH Configuration\n\nCreate or edit the SSH config file for easier connections:\n```bash\nmkdir -p ~/.ssh\ncat > ~/.ssh/config << 'EOF'\nHost alias\n    HostName hostname_or_ip\n    User username\n    IdentityFile ~/.ssh/key_name\n    Port 22\n    ServerAliveInterval 60\nEOF\nchmod 600 ~/.ssh/config\n```\n\nThen connect using the alias:\n```bash\nssh alias\n```\n\n## Common SSH Options\n\n- `-p PORT`: Connect to a specific port\n- `-X`: Enable X11 forwarding\n- `-L local_port:remote_host:remote_port`: Set up local port forwarding\n- `-R remote_port:local_host:local_port`: Set up remote port forwarding\n- `-N`: Do not execute a remote command (useful for port forwarding)\n- `-f`: Run in background\n- `-v`: Verbose mode (add more v's for increased verbosity)\n\n## File Transfer with SCP\n\nCopy a file to the remote server:\n```bash\nscp /path/to/local/file username@hostname:/path/to/remote/directory/\n```\n\nCopy a file from the remote server:\n```bash\nscp username@hostname:/path/to/remote/file /path/to/local/directory/\n```\n\nCopy a directory recursively:\n```bash\nscp -r /path/to/local/directory username@hostname:/path/to/remote/directory/\n```\n\n## SSH Agent\n\nStart the SSH agent:\n```bash\neval \"$(ssh-agent -s)\"\n```\n\nAdd a key to the agent:\n```bash\nssh-add ~/.ssh/key_name\n```\n\n## Troubleshooting\n\n- Check SSH service status on remote: `systemctl status sshd`\n- Verify SSH port is open: `nc -zv hostname 22`\n- Debug connection issues: `ssh -vvv username@hostname`\n- Check permissions: SSH private keys should have 600 permissions (`chmod 600 ~/.ssh/key_name`)\n- Verify known_hosts: If host key changed, remove the old entry with `ssh-keygen -R hostname`\n\n## Secure SSH Key Management\n\n### Local Storage with Proper Permissions\n\nThe most basic approach is to ensure proper file permissions:\n\n```bash\n# Set correct permissions for private keys\nchmod 600 ~/.ssh/id_ed25519\n# Set correct permissions for public keys\nchmod 644 ~/.ssh/id_ed25519.pub\n# Set correct permissions for SSH directory\nchmod 700 ~/.ssh\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "ssh",
                "remote server",
                "remote machine",
                "remote host",
                "remote connection",
                "secure shell",
                "ssh keys"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/ssh/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Establish and manage SSH connections to remote machines, including key generation, configuration, and file transfers. Use when connecting to remote servers, executing remote commands, or transferring files via SCP."
          },
          {
            "name": "github",
            "content": "You have access to an environment variable, `GITHUB_TOKEN`, which allows you to interact with\nthe GitHub API.\n\n<IMPORTANT>\nYou can use `curl` with the `GITHUB_TOKEN` to interact with GitHub's API.\nALWAYS use the GitHub API for operations instead of a web browser.\nALWAYS use the `create_pr` tool to open a pull request\nIf the user asks you to check GitHub Actions status, first try to use `gh` to work with workflows, and only fallback to basic API calls if that fails.\nExamples:\n- `gh run watch` (https://cli.github.com/manual/gh_run_watch) to monitor workflow runs\n- `gh pr checks 200 --watch --interval 10` to check until completed.\n</IMPORTANT>\n\nIf you encounter authentication issues when pushing to GitHub (such as password prompts or permission errors), the old token may have expired. In such case, update the remote URL to include the current token: `git remote set-url origin https://${GITHUB_TOKEN}@github.com/username/repo.git`\n\nHere are some instructions for pushing, but ONLY do this if the user asks you to:\n* NEVER push directly to the `main` or `master` branch\n* Git config (username and email) is pre-set. Do not modify.\n* You may already be on a branch starting with `openhands-workspace`. Create a new branch with a better name before pushing.\n* Use the `create_pr` tool to create a pull request, if you haven't already\n* Once you've created your own branch or a pull request, continue to update it. Do NOT create a new one unless you are explicitly asked to. Update the PR title and description as necessary, but don't change the branch name.\n* Use the main branch as the base branch, unless the user requests otherwise\n* After opening or updating a pull request, send the user a short message with a link to the pull request.\n* Do NOT mark a pull request as ready to review unless the user explicitly says so\n* Do all of the above in as few steps as possible. E.g. you could push changes with one step by running the following bash commands:\n```bash\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "github",
                "git"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/github/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Interact with GitHub repositories, pull requests, issues, and workflows using the GITHUB_TOKEN environment variable and GitHub CLI. Use when working with code hosted on GitHub or managing GitHub resources."
          },
          {
            "name": "datadog",
            "content": "# Datadog\n\n<IMPORTANT>\nBefore performing any Datadog operations, first check if the required environment variables are set:\n\n```bash\n[ -n \"$DD_API_KEY\" ] && echo \"DD_API_KEY is set\" || echo \"DD_API_KEY is NOT set\"\n[ -n \"$DD_APP_KEY\" ] && echo \"DD_APP_KEY is set\" || echo \"DD_APP_KEY is NOT set\"\n[ -n \"$DD_SITE\" ] && echo \"DD_SITE is set\" || echo \"DD_SITE is NOT set\"\n```\n\nIf any of these variables are missing, ask the user to provide them before proceeding:\n- **DD_API_KEY**: Datadog API key\n- **DD_APP_KEY**: Datadog Application key\n- **DD_SITE**: Datadog site (e.g., `datadoghq.com`, `datadoghq.eu`, `us3.datadoghq.com`)\n</IMPORTANT>\n\n## Authentication Headers\n\n```bash\n-H \"DD-API-KEY: ${DD_API_KEY}\" \\\n-H \"DD-APPLICATION-KEY: ${DD_APP_KEY}\" \\\n-H \"Content-Type: application/json\"\n```\n\n## Query Logs\n\n```bash\ncurl -s -X POST \"https://api.${DD_SITE}/api/v2/logs/events/search\" \\\n  -H \"DD-API-KEY: ${DD_API_KEY}\" \\\n  -H \"DD-APPLICATION-KEY: ${DD_APP_KEY}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"filter\": {\n      \"query\": \"service:my-service status:error\",\n      \"from\": \"now-1h\",\n      \"to\": \"now\"\n    },\n    \"sort\": \"-timestamp\",\n    \"page\": {\"limit\": 50}\n  }' | jq .\n```\n\n## Query Metrics\n\n```bash\ncurl -s -G \"https://api.${DD_SITE}/api/v1/query\" \\\n  -H \"DD-API-KEY: ${DD_API_KEY}\" \\\n  -H \"DD-APPLICATION-KEY: ${DD_APP_KEY}\" \\\n  --data-urlencode \"query=avg:system.cpu.user{*}\" \\\n  --data-urlencode \"from=$(date -d '1 hour ago' +%s)\" \\\n  --data-urlencode \"to=$(date +%s)\" | jq .\n```\n\n## Query APM Traces\n\n```bash\ncurl -s -X POST \"https://api.${DD_SITE}/api/v2/spans/events/search\" \\\n  -H \"DD-API-KEY: ${DD_API_KEY}\" \\\n  -H \"DD-APPLICATION-KEY: ${DD_APP_KEY}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"filter\": {\n      \"query\": \"service:my-service\",\n      \"from\": \"now-1h\",\n      \"to\": \"now\"\n    },\n    \"sort\": \"-timestamp\",\n    \"page\": {\"limit\": 25}\n  }' | jq .\n```\n\n## List Monitors\n\n```bash\ncurl -s -G \"https://api.${DD_SITE}/api/v1/monitor\" \\\n  -H \"DD-API-KEY: ${DD_API_KEY}\" \\\n  -H \"DD-APPLICATION-KEY: ${DD_APP_KEY}\" | jq .\n```\n\n## Documentation\n\n- [Logs API](https://docs.datadoghq.com/api/latest/logs/)\n- [Metrics API](https://docs.datadoghq.com/api/latest/metrics/)\n- [APM/Tracing API](https://docs.datadoghq.com/api/latest/tracing/)\n- [Monitors API](https://docs.datadoghq.com/api/latest/monitors/)\n- [Events API](https://docs.datadoghq.com/api/latest/events/)\n- [Dashboards API](https://docs.datadoghq.com/api/latest/dashboards/)",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "datadog"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/datadog/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Query and analyze Datadog logs, metrics, APM traces, and monitors using the Datadog API. Use when debugging production issues, monitoring application performance, or investigating alerts."
          },
          {
            "name": "onboarding-agent",
            "content": "# First-time User Conversation with OpenHands\n\n## Skill purpose\nIn **<= 5 progressive questions**, interview the user to identify their coding goal and constraints, then generate a **concrete, step-by-step plan** that maximizes the likelihood of a **successful pull request (PR)**.\nFinish by asking: **\u201cDo you want me to execute the plan?\u201d**\n\n## Guardrails\n- Ask **no more than 5 questions total** (stop early if you have enough info).\n- **Progressive:** each next question builds on the previous answer.\n- Keep questions concise (**<= 2 sentences** each). Offer options when useful.\n- If the user is uncertain, propose **reasonable defaults** and continue.\n- Stop once you have enough info to create a **specific PR-ready plan**.\n- NEVER push directly to the main or master branch. Do not automatically commit any changes to the repo.\n\n## Interview Flow\n\n### **First question - always start here**\n> \u201cGreat \u2014 what are you trying to build or change, in one or two sentences?\n> (e.g., add an endpoint, fix a bug, write a script, tweak UI)\u201d\n\n### **Dynamic follow-up questions**\nChoose the next question based on what's most relevant from the last reply.\nUse one at a time - no more than 5 total.\n\n#### 1. Repo & Runtime Context\n- \u201cWhere will this live? Repo/name or link, language/runtime, and framework (if any)?\u201d\n- \u201cHow do you run and test locally? (package manager, build tool, dev server, docker compose?)\u201d\n\n#### 2. Scope & Acceptance Criteria\n- \u201cWhat's the smallest valuable change we can ship first? Describe the exact behavior or API/CLI/UI change and how we\u2019ll verify it.\u201d\n- \u201cAny non-negotiables? (performance, accessibility, security, backwards-compatibility)\u201d\n\n#### 3. Interfaces & Data\n- \u201cWhich interfaces are affected? (files, modules, routes, DB tables, events, components)\u201d\n- \u201cDo we need new schema/DTOs, migrations, or mock data?\u201d\n\n#### 4. Testing & Tooling\n- \u201cWhat tests should prove it works (unit/integration/e2e)? Which test framework, and any CI requirements?\u201d\n\n#### 5. Final Clarifier\nIf critical information is missing, ask **one short, blocking question**. If not, skip directly to the plan.\n\n## Plan Generation (After Questions)\nProduce a **PR-ready plan** customized to the user\u2019s answers, in this structure:\n\n### 1. Goal & Success Criteria\n- One-sentence goal.\n- Bullet **acceptance tests** (observable behaviors or API/CLI examples).\n\n### 2. Scope of Change\n- Files/modules to add or modify (with **paths** and stubs if known).\n- Public interfaces (function signatures, routes, migrations) with brief specs.\n\n### 3. Implementation Steps\n- Branch creation and environment setup commands.\n- Code tasks broken into <= 8 bite-sized commits.\n- Any scaffolding or codegen commands.\n\n### 4. Testing Plan\n- Tests to write, where they live, and example test names.\n- How to run them locally and in CI (with exact commands).\n- Sample fixtures/mocks or seed data.\n\n### 5. Quality Gates & Tooling\n- Lint/format/type-check commands.\n- Security/performance checks if relevant.\n- Accessibility checks for UI work.\n\n### 6. Risks & Mitigations\n- Top 3 risks + how to detect or rollback.\n- Mention feature flag/env toggle if applicable.\n\n### 7. Timeline & Next Steps\n- Rough estimate (S/M/L) with ordered sequence.\n- Call out anything **explicitly out of scope**.\n\n## Final Question\n**\u201cDo you want me to execute the plan?\u201d**",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "/onboard"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/onboarding-agent/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Interactive onboarding workflow that interviews users to understand their coding goals and generates PR-ready implementation plans. Use when starting a new development task to ensure clear requirements and structured execution."
          },
          {
            "name": "agent-memory",
            "content": "* Repository memory: Use AGENTS.md in each repository root to store and access important information.\n  - If this file exists, it will be added to your context automatically.\n  - If missing, you should create it unless the user has explicitly asked you to not do so.\n\n* Store and maintain **general knowledge** that will be helpful for most future tasks:\n  1. Repository structure\n  2. Common commands (build, lint, test, pre-commit, etc.)\n  3. Code style preferences\n  4. Workflows and best practices\n  5. Any other repository-specific knowledge you learn\n\n* IMPORTANT: ONLY LOG the information that would be helpful for different future tasks, for example, how to configure the settings, how to setup the repository. Do NOT add issue-specific information (e.g., what specific error you have ran into and how you fix it).\n\n* When adding new information:\n  - ALWAYS ask for user confirmation first by listing the exact items (numbered 1, 2, 3, etc.) you plan to save to repo.md\n  - Only save the items the user approves (they may ask you to save a subset)\n  - Ensure it integrates nicely with existing knowledge in repo.md\n  - Reorganize the content if needed to maintain clarity and organization\n  - Group related information together under appropriate sections or headings\n  - If you've only explored a portion of the codebase, clearly note this limitation in the repository structure documentation\n  - If you don't know the essential commands for working with the repository, such as lint or typecheck, ask the user and suggest adding them to repo.md for future reference (with permission)\n\nWhen you receive this message, please review and summarize your recent actions and observations, then present a list of valuable information that should be saved in AGENTS.md to the user.",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "/remember"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/agent-memory/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Persist and retrieve repository-specific knowledge using AGENTS.md files. Use when you want to save important information about a codebase (build commands, code style, workflows) for future sessions."
          },
          {
            "name": "frontend-design",
            "content": "This skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: OpenHands is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/frontend-design/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). Generates creative, polished code and UI design that avoids generic AI aesthetics.",
            "license": "Complete terms in LICENSE.txt"
          },
          {
            "name": "bitbucket",
            "content": "You have access to an environment variable, `BITBUCKET_TOKEN`, which allows you to interact with\nthe Bitbucket API.\n\n<IMPORTANT>\nYou can use `curl` with the `BITBUCKET_TOKEN` to interact with Bitbucket's API.\nALWAYS use the Bitbucket API for operations instead of a web browser.\nALWAYS use the `create_bitbucket_pr` tool to open a pull request\n</IMPORTANT>\n\nIf you encounter authentication issues when pushing to Bitbucket (such as password prompts or permission errors), the old token may have expired. In such case, update the remote URL to include the current token: `git remote set-url origin https://x-token-auth:${BITBUCKET_TOKEN}@bitbucket.org/username/repo.git`\n\nHere are some instructions for pushing, but ONLY do this if the user asks you to:\n* NEVER push directly to the `main` or `master` branch\n* Git config (username and email) is pre-set. Do not modify.\n* You may already be on a branch starting with `openhands-workspace`. Create a new branch with a better name before pushing.\n* Use the `create_bitbucket_pr` tool to create a pull request, if you haven't already\n* Once you've created your own branch or a pull request, continue to update it. Do NOT create a new one unless you are explicitly asked to. Update the PR title and description as necessary, but don't change the branch name.\n* Use the main branch as the base branch, unless the user requests otherwise\n* After opening or updating a pull request, send the user a short message with a link to the pull request.\n* Do NOT mark a pull request as ready to review unless the user explicitly says so\n* Do all of the above in as few steps as possible. E.g. you could push changes with one step by running the following bash commands:\n```bash\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "bitbucket",
                "git"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/bitbucket/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Interact with Bitbucket repositories and pull requests using the BITBUCKET_TOKEN environment variable. Use when working with code hosted on Bitbucket or managing Bitbucket resources via API."
          },
          {
            "name": "kubernetes",
            "content": "# Kubernetes Local Development with KIND\n\n## KIND Installation and Setup\n\nKIND (Kubernetes IN Docker) is a tool for running local Kubernetes clusters using Docker containers as nodes. It's designed for testing Kubernetes applications locally.\n\nIMPORTANT: Before you proceed with installation, make sure you have docker installed locally.\n\n### Installation\n\nTo install KIND on a Debian/Ubuntu system:\n\n```bash\n# Download KIND binary\ncurl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.22.0/kind-linux-amd64\n# Make it executable\nchmod +x ./kind\n# Move to a directory in your PATH\nsudo mv ./kind /usr/local/bin/\n```\n\nTo install kubectl:\n\n```bash\n# Download kubectl\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n# Make it executable\nchmod +x kubectl\n# Move to a directory in your PATH\nsudo mv ./kubectl /usr/local/bin/\n```\n\n### Creating a Cluster\n\nCreate a basic KIND cluster:\n\n```bash\nkind create cluster\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "kubernetes",
                "k8s",
                "kube"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/kubernetes/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Set up and manage local Kubernetes clusters using KIND (Kubernetes IN Docker). Use when testing Kubernetes applications locally or developing cloud-native workloads."
          },
          {
            "name": "releasenotes",
            "content": "Generate a changelog for all changes from the most recent release until now.\n\n## Steps\n1. Find the most recent release tag using `git tag --sort=-creatordate`\n2. Get commits and merged PRs since that tag\n3. Look at previous releases in this repo to match their format and style\n4. Categorize changes into sections: Breaking Changes, Added, Changed, Fixed, Notes\n5. Focus on user-facing changes (features, important bug fixes, breaking changes)\n6. Include PR links and contributor attribution\n\n## Output\nPresent the changelog in a markdown code block, ready to copy-paste into a GitHub release.",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "/releasenotes"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/releasenotes/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Generate formatted changelogs from git history since the last release tag. Use when preparing release notes that categorize changes into breaking changes, features, fixes, and other sections."
          },
          {
            "name": "jupyter",
            "content": "# Jupyter Notebook Guide\n\nNotebooks are JSON files. Cells are in `nb['cells']`, each has `source` (list of strings) and `cell_type` ('code', 'markdown', or 'raw').\n\n## Modifying Notebooks\n```python\nimport json\nwith open('notebook.ipynb') as f:\n    nb = json.load(f)\n# Modify nb['cells'][i]['source'], then:\nwith open('notebook.ipynb', 'w') as f:\n    json.dump(nb, f, indent=1)\n```\n\n## Executing & Converting\n```bash\njupyter nbconvert --to notebook --execute --inplace notebook.ipynb  # Execute in place\njupyter nbconvert --to html notebook.ipynb      # Convert to HTML\njupyter nbconvert --to script notebook.ipynb    # Convert to Python\njupyter nbconvert --to markdown notebook.ipynb  # Convert to Markdown\n```\n\n## Finding Code\n```bash\ngrep -n \"search_term\" notebook.ipynb\n```\n\n## Cell Structure\n```python\n# Code cell\n{\"cell_type\": \"code\", \"execution_count\": None, \"metadata\": {}, \"outputs\": [], \"source\": [\"code\\n\"]}\n# Markdown cell\n{\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"# Title\\n\"]}\n```\n\n## Clear Outputs\n```python\nfor cell in nb['cells']:\n    if cell['cell_type'] == 'code':\n        cell['outputs'] = []\n        cell['execution_count'] = None\n```",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "ipynb",
                "jupyter"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/jupyter/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Read, modify, execute, and convert Jupyter notebooks programmatically. Use when working with .ipynb files for data science workflows, including editing cells, clearing outputs, or converting to other formats."
          },
          {
            "name": "npm",
            "content": "When using npm to install packages, you will not be able to use an interactive shell, and it may be hard to confirm your actions.\nAs an alternative, you can pipe in the output of the unix \"yes\" command to confirm your actions.",
            "trigger": {
              "type": "keyword",
              "keywords": [
                "npm"
              ]
            },
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/npm/SKILL.md",
            "inputs": [],
            "is_agentskills_format": true,
            "description": "Handle npm package installation in non-interactive environments by piping confirmations. Use when installing Node.js packages that require user confirmation prompts."
          },
          {
            "name": "skills/skill-creator/references/workflows",
            "content": "# Workflow Patterns\n\n## Sequential Workflows\n\nFor complex tasks, break operations into clear, sequential steps. It is often helpful to give OpenHands an overview of the process towards the beginning of SKILL.md:\n\n```markdown\nFilling a PDF form involves these steps:\n\n1. Analyze the form (run analyze_form.py)\n2. Create field mapping (edit fields.json)\n3. Validate mapping (run validate_fields.py)\n4. Fill the form (run fill_form.py)\n5. Verify output (run verify_output.py)\n```\n\n## Conditional Workflows\n\nFor tasks with branching logic, guide OpenHands through decision points:\n\n```markdown\n1. Determine the modification type:\n   **Creating new content?** \u2192 Follow \"Creation workflow\" below\n   **Editing existing content?** \u2192 Follow \"Editing workflow\" below\n\n2. Creation workflow: [steps]\n3. Editing workflow: [steps]\n```",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/skill-creator/references/workflows.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/skill-creator/references/output-patterns",
            "content": "# Output Patterns\n\nUse these patterns when skills need to produce consistent, high-quality output.\n\n## Template Pattern\n\nProvide templates for output format. Match the level of strictness to your needs.\n\n**For strict requirements (like API responses or data formats):**\n\n```markdown\n## Report structure\n\nALWAYS use this exact template structure:\n\n# [Analysis Title]\n\n## Executive summary\n[One-paragraph overview of key findings]\n\n## Key findings\n- Finding 1 with supporting data\n- Finding 2 with supporting data\n- Finding 3 with supporting data\n\n## Recommendations\n1. Specific actionable recommendation\n2. Specific actionable recommendation\n```\n\n**For flexible guidance (when adaptation is useful):**\n\n```markdown\n## Report structure\n\nHere is a sensible default format, but use your best judgment:\n\n# [Analysis Title]\n\n## Executive summary\n[Overview]\n\n## Key findings\n[Adapt sections based on what you discover]\n\n## Recommendations\n[Tailor to the specific context]\n\nAdjust sections as needed for the specific analysis type.\n```\n\n## Examples Pattern\n\nFor skills where output quality depends on seeing examples, provide input/output pairs:\n\n```markdown\n## Commit message format\n\nGenerate commit messages following these examples:\n\n**Example 1:**\nInput: Added user authentication with JWT tokens\nOutput:\n```\nfeat(auth): implement JWT-based authentication\n\nAdd login endpoint and token validation middleware\n```\n\n**Example 2:**\nInput: Fixed bug where dates displayed incorrectly in reports\nOutput:\n```\nfix(reports): correct date formatting in timezone conversion\n\nUse UTC timestamps consistently across report generation\n```\n\nFollow this style: type(scope): brief description, then detailed explanation.\n```\n\nExamples help OpenHands understand the desired style and level of detail more clearly than descriptions alone.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/skill-creator/references/output-patterns.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/readiness-report/references/criteria",
            "content": "# Agent Readiness Criteria\n\nComplete reference of all 81 criteria evaluated across nine technical pillars.\n\n## Criteria Format\n\nEach criterion is binary (pass/fail) and includes:\n- **ID**: Unique identifier (snake_case)\n- **Level**: Maturity level (1-5) where criterion is evaluated\n- **Detection**: How to check if the criterion is met\n- **Impact**: What happens when this criterion fails\n\n---\n\n## 1. Style & Validation\n\nAutomated tools that catch bugs instantly. Without them, agents waste cycles on syntax errors and style drift.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `formatter` | 1 | Prettier, Black, Ruff format, gofmt config exists | Agent submits code with formatting issues, waits for CI, fixes blindly |\n| `lint_config` | 1 | ESLint, Ruff, golangci-lint, or language-specific linter configured | Style inconsistencies accumulate, harder to review |\n| `type_check` | 1 | TypeScript strict, mypy, Go (static by default) | Type errors caught late in CI instead of immediately |\n| `strict_typing` | 2 | TypeScript strict:true, mypy strict=true | Partial typing allows bugs to slip through |\n| `pre_commit_hooks` | 2 | .pre-commit-config.yaml or Husky config | Checks run in CI instead of locally, slower feedback |\n| `naming_consistency` | 2 | Linter rules or documented conventions | Inconsistent names make codebase harder to navigate |\n| `large_file_detection` | 2 | Git LFS, pre-commit check-added-large-files | Large files bloat repository, slow clones |\n| `code_modularization` | 3 | import-linter, Nx boundaries, Bazel modules | Architecture degrades over time |\n| `cyclomatic_complexity` | 3 | gocyclo, lizard, radon, SonarQube | Complex functions harder to understand and modify |\n| `dead_code_detection` | 3 | vulture, knip, deadcode in CI | Unused code clutters codebase |\n| `duplicate_code_detection` | 3 | jscpd, PMD CPD, SonarQube | Duplicated code increases maintenance burden |\n| `tech_debt_tracking` | 4 | TODO scanner, SonarQube, linter TODO rules | Tech debt accumulates without visibility |\n| `n_plus_one_detection` | 4 | nplusone, bullet gem, query analyzer | Performance issues in database queries |\n\n---\n\n## 2. Build System\n\nFast, reliable builds enable rapid iteration. Slow CI kills agent productivity.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `build_cmd_doc` | 1 | Build commands documented in README/AGENTS.md | Agent doesn't know how to build |\n| `deps_pinned` | 1 | Lockfile exists (package-lock.json, uv.lock, go.sum) | Non-reproducible builds |\n| `vcs_cli_tools` | 1 | gh/glab CLI authenticated | Can't interact with PRs/issues |\n| `fast_ci_feedback` | 2 | CI completes in <10 minutes | Agent waits too long for feedback |\n| `single_command_setup` | 2 | One command to set up dev environment | Agent can't bootstrap quickly |\n| `release_automation` | 2 | Automated release workflow exists | Manual releases slow deployment |\n| `deployment_frequency` | 2 | Regular releases (weekly+) | Infrequent deploys signal process issues |\n| `release_notes_automation` | 3 | Auto-generated changelogs/release notes | Manual release notes are error-prone |\n| `agentic_development` | 3 | AI agent commits visible in history | No prior agent integration |\n| `automated_pr_review` | 3 | Danger.js, automated review bots | Reviews require human intervention |\n| `feature_flag_infrastructure` | 3 | LaunchDarkly, Statsig, Unleash, custom system | Hard to ship incrementally |\n| `build_performance_tracking` | 4 | Build caching, timing metrics | Build times creep up unnoticed |\n| `heavy_dependency_detection` | 4 | Bundle size analysis (webpack-bundle-analyzer) | Bundle bloat goes unnoticed |\n| `unused_dependencies_detection` | 4 | depcheck, deptry in CI | Bloated dependency tree |\n| `dead_feature_flag_detection` | 4 | Stale flag detection tooling | Abandoned flags clutter code |\n| `monorepo_tooling` | 4 | Nx, Turborepo, Bazel for monorepos | Cross-package changes are error-prone |\n| `version_drift_detection` | 4 | Version consistency checks | Packages diverge silently |\n| `progressive_rollout` | 5 | Canary deploys, gradual rollouts | All-or-nothing deployments are risky |\n| `rollback_automation` | 5 | One-click rollback capability | Slow recovery from bad deploys |\n\n---\n\n## 3. Testing\n\nTests verify that changes work. Without them, agents can't validate their own work.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `unit_tests_exist` | 1 | Test files present (*_test.*, *.spec.*) | No way to verify basic correctness |\n| `unit_tests_runnable` | 1 | Test command documented and works | Agent can't run tests |\n| `test_naming_conventions` | 2 | Consistent test file naming | Tests hard to find |\n| `test_isolation` | 2 | Tests can run in parallel | Slow test runs |\n| `integration_tests_exist` | 3 | E2E/integration test directory | Only unit-level coverage |\n| `test_coverage_thresholds` | 3 | Coverage enforcement in CI | Coverage drifts down |\n| `flaky_test_detection` | 4 | Test retry, quarantine, or tracking | Flaky tests erode trust |\n| `test_performance_tracking` | 4 | Test timing metrics | Slow tests accumulate |\n\n---\n\n## 4. Documentation\n\nDocumentation tells the agent what it needs to know. Missing docs mean wasted exploration.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `readme` | 1 | README.md exists with setup instructions | Agent doesn't know project basics |\n| `agents_md` | 2 | AGENTS.md or CLAUDE.md exists | Agent lacks operational guidance |\n| `documentation_freshness` | 2 | Key docs updated in last 180 days | Stale docs mislead agent |\n| `api_schema_docs` | 3 | OpenAPI spec, GraphQL schema, or API docs | Agent must reverse-engineer APIs |\n| `automated_doc_generation` | 3 | Doc generation in CI | Docs drift from code |\n| `service_flow_documented` | 3 | Architecture diagrams (mermaid, PlantUML) | Agent lacks system context |\n| `skills` | 3 | Skills directory (.claude/skills/, .factory/skills/) | No specialized agent instructions |\n| `agents_md_validation` | 4 | CI validates AGENTS.md commands work | AGENTS.md becomes stale |\n\n---\n\n## 5. Dev Environment\n\nReproducible environments prevent \"works on my machine\" issues.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `env_template` | 2 | .env.example or documented env vars | Agent guesses at configuration |\n| `devcontainer` | 3 | .devcontainer/devcontainer.json exists | Environment setup is manual |\n| `devcontainer_runnable` | 3 | Devcontainer builds and works | Devcontainer is broken |\n| `database_schema` | 3 | Schema files or migration directory | Database structure undocumented |\n| `local_services_setup` | 3 | docker-compose.yml for dependencies | External services need manual setup |\n\n---\n\n## 6. Debugging & Observability\n\nWhen things go wrong, observability helps diagnose issues quickly.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `structured_logging` | 2 | Logging library with structured output | Logs hard to parse |\n| `code_quality_metrics` | 2 | Coverage reporting in CI | No visibility into code quality |\n| `error_tracking_contextualized` | 3 | Sentry, Bugsnag with context | Errors lack context for debugging |\n| `distributed_tracing` | 3 | OpenTelemetry, trace IDs | Can't trace requests across services |\n| `metrics_collection` | 3 | Prometheus, Datadog, or custom metrics | No runtime visibility |\n| `health_checks` | 3 | Health/readiness endpoints | Can't verify service status |\n| `profiling_instrumentation` | 4 | CPU/memory profiling tools | Performance issues hard to diagnose |\n| `alerting_configured` | 4 | PagerDuty, OpsGenie, alert rules | Issues discovered late |\n| `deployment_observability` | 4 | Deploy tracking, dashboards | Can't correlate issues to deploys |\n| `runbooks_documented` | 4 | Runbooks directory or linked docs | No guidance for incident response |\n| `circuit_breakers` | 5 | Resilience patterns implemented | Cascading failures |\n\n---\n\n## 7. Security\n\nSecurity criteria protect the codebase and data.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `gitignore_comprehensive` | 1 | .gitignore excludes secrets, build artifacts | Sensitive files committed |\n| `secrets_management` | 2 | GitHub secrets, vault, cloud secrets | Hardcoded secrets |\n| `codeowners` | 2 | CODEOWNERS file exists | No clear ownership |\n| `branch_protection` | 2 | Protected main branch | Unreviewed changes to main |\n| `dependency_update_automation` | 3 | Dependabot, Renovate configured | Dependencies go stale |\n| `log_scrubbing` | 3 | Log sanitization for PII | Sensitive data in logs |\n| `pii_handling` | 3 | PII redaction mechanisms | PII exposure risk |\n| `automated_security_review` | 4 | CodeQL, Snyk, SonarQube in CI | Security issues caught late |\n| `secret_scanning` | 4 | GitHub secret scanning enabled | Leaked credentials |\n| `dast_scanning` | 5 | Dynamic security testing | Runtime vulnerabilities missed |\n| `privacy_compliance` | 5 | GDPR/privacy tooling | Compliance gaps |\n\n---\n\n## 8. Task Discovery\n\nStructured task management helps agents find and understand work.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `issue_templates` | 2 | .github/ISSUE_TEMPLATE/ exists | Inconsistent issue quality |\n| `issue_labeling_system` | 2 | Consistent labels on issues | Issues hard to categorize |\n| `pr_templates` | 2 | pull_request_template.md exists | PRs lack context |\n| `backlog_health` | 3 | Issues have descriptive titles, labels | Unclear what to work on |\n\n---\n\n## 9. Product & Analytics\n\nConnect errors to insights and understand user behavior.\n\n| Criterion | Level | Detection | Impact |\n|-----------|-------|-----------|--------|\n| `error_to_insight_pipeline` | 5 | Sentry-GitHub issue creation automation | Errors don't become actionable issues |\n| `product_analytics_instrumentation` | 5 | Mixpanel, Amplitude, PostHog, Heap | No user behavior data to inform decisions |\n\n---\n\n## Skipped Criteria\n\nSome criteria are skipped based on repository type:\n- **Libraries**: Skip deployment-related criteria (progressive_rollout, health_checks)\n- **CLI tools**: Skip web-specific criteria (dast_scanning)\n- **Database projects**: Skip N+1 detection (they ARE the database)\n- **Single apps**: Skip monorepo tooling criteria\n\nThe analysis script automatically determines which criteria to skip based on detected repository characteristics.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/readiness-report/references/criteria.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/readiness-report/references/maturity-levels",
            "content": "# Maturity Levels\n\nRepositories progress through five levels. Each level represents a qualitative shift in what autonomous agents can accomplish.\n\n## Level Progression Rules\n\n1. **80% Threshold**: To unlock a level, pass \u226580% of criteria at that level\n2. **Cumulative**: Must also pass all previous levels at 80%+\n3. **Binary Criteria**: Each criterion is pass/fail (no partial credit)\n4. **Skipped Criteria**: Not applicable criteria are excluded from the calculation\n\n---\n\n## Level 1: Initial\n\n**Status**: Basic version control  \n**Agent Capability**: Manual assistance only\n\n### Requirements\nThe bare minimum for any collaborative development.\n\n| Criterion | Pillar |\n|-----------|--------|\n| `formatter` | Style & Validation |\n| `lint_config` | Style & Validation |\n| `type_check` | Style & Validation |\n| `build_cmd_doc` | Build System |\n| `deps_pinned` | Build System |\n| `vcs_cli_tools` | Build System |\n| `unit_tests_exist` | Testing |\n| `unit_tests_runnable` | Testing |\n| `readme` | Documentation |\n| `gitignore_comprehensive` | Security |\n\n### What Agents Can Do\n- Read and understand code\n- Make simple edits with manual verification\n- Cannot reliably validate their own changes\n\n### What's Missing\nWithout L1, agents operate blind\u2014no way to verify builds, run tests, or ensure code quality.\n\n---\n\n## Level 2: Managed\n\n**Status**: Basic CI/CD and testing  \n**Agent Capability**: Simple, well-defined tasks\n\n### Requirements\nFoundational automation and documentation.\n\n| Criterion | Pillar |\n|-----------|--------|\n| `strict_typing` | Style & Validation |\n| `pre_commit_hooks` | Style & Validation |\n| `naming_consistency` | Style & Validation |\n| `large_file_detection` | Style & Validation |\n| `fast_ci_feedback` | Build System |\n| `single_command_setup` | Build System |\n| `release_automation` | Build System |\n| `deployment_frequency` | Build System |\n| `test_naming_conventions` | Testing |\n| `test_isolation` | Testing |\n| `agents_md` | Documentation |\n| `documentation_freshness` | Documentation |\n| `env_template` | Dev Environment |\n| `structured_logging` | Observability |\n| `code_quality_metrics` | Observability |\n| `secrets_management` | Security |\n| `codeowners` | Security |\n| `branch_protection` | Security |\n| `issue_templates` | Task Discovery |\n| `issue_labeling_system` | Task Discovery |\n| `pr_templates` | Task Discovery |\n\n### What Agents Can Do\n- Fix simple, well-scoped bugs\n- Make straightforward changes with fast feedback\n- Run tests and verify basic correctness\n\n### What's Missing\nWithout L2, feedback loops are too slow. Agents wait minutes for CI instead of seconds for local checks.\n\n---\n\n## Level 3: Standardized\n\n**Status**: Production-ready for agents  \n**Agent Capability**: Routine maintenance\n\n### Requirements\nClear processes defined and enforced. This is the target for most teams.\n\n| Criterion | Pillar |\n|-----------|--------|\n| `code_modularization` | Style & Validation |\n| `cyclomatic_complexity` | Style & Validation |\n| `dead_code_detection` | Style & Validation |\n| `duplicate_code_detection` | Style & Validation |\n| `release_notes_automation` | Build System |\n| `agentic_development` | Build System |\n| `automated_pr_review` | Build System |\n| `feature_flag_infrastructure` | Build System |\n| `integration_tests_exist` | Testing |\n| `test_coverage_thresholds` | Testing |\n| `api_schema_docs` | Documentation |\n| `automated_doc_generation` | Documentation |\n| `service_flow_documented` | Documentation |\n| `skills` | Documentation |\n| `devcontainer` | Dev Environment |\n| `devcontainer_runnable` | Dev Environment |\n| `database_schema` | Dev Environment |\n| `local_services_setup` | Dev Environment |\n| `error_tracking_contextualized` | Observability |\n| `distributed_tracing` | Observability |\n| `metrics_collection` | Observability |\n| `health_checks` | Observability |\n| `dependency_update_automation` | Security |\n| `log_scrubbing` | Security |\n| `pii_handling` | Security |\n| `backlog_health` | Task Discovery |\n\n### What Agents Can Do\n- Bug fixes and routine maintenance\n- Test additions and documentation updates\n- Dependency upgrades with confidence\n- Feature work with clear specifications\n\n### Example Repositories at L3\n- FastAPI\n- GitHub CLI\n- pytest\n\n---\n\n## Level 4: Measured\n\n**Status**: Comprehensive automation  \n**Agent Capability**: Complex features\n\n### Requirements\nAdvanced tooling and metrics for optimization.\n\n| Criterion | Pillar |\n|-----------|--------|\n| `tech_debt_tracking` | Style & Validation |\n| `n_plus_one_detection` | Style & Validation |\n| `build_performance_tracking` | Build System |\n| `unused_dependencies_detection` | Build System |\n| `dead_feature_flag_detection` | Build System |\n| `monorepo_tooling` | Build System |\n| `version_drift_detection` | Build System |\n| `flaky_test_detection` | Testing |\n| `test_performance_tracking` | Testing |\n| `agents_md_validation` | Documentation |\n| `profiling_instrumentation` | Observability |\n| `alerting_configured` | Observability |\n| `deployment_observability` | Observability |\n| `runbooks_documented` | Observability |\n| `automated_security_review` | Security |\n| `secret_scanning` | Security |\n\n### What Agents Can Do\n- Complex multi-file refactors\n- Performance optimization with data\n- Architecture improvements\n- Security hardening\n\n### Example Repositories at L4\n- CockroachDB\n- Temporal\n\n---\n\n## Level 5: Optimized\n\n**Status**: Full autonomous capability  \n**Agent Capability**: End-to-end development\n\n### Requirements\nComprehensive observability, security, and automation.\n\n| Criterion | Pillar |\n|-----------|--------|\n| `progressive_rollout` | Build System |\n| `rollback_automation` | Build System |\n| `circuit_breakers` | Observability |\n| `dast_scanning` | Security |\n| `privacy_compliance` | Security |\n| `error_to_insight_pipeline` | Task Discovery |\n| `product_analytics_instrumentation` | Task Discovery |\n\n### What Agents Can Do\n- Full feature development with minimal oversight\n- Incident response and remediation\n- Autonomous triage and prioritization\n- Continuous improvement of the codebase itself\n\n### What L5 Looks Like\nVery few repositories achieve L5. It requires mature DevOps, comprehensive observability, and sophisticated automation.\n\n---\n\n## Calculating Scores\n\n### Repository Score\n```\nPass Rate = (Passed Criteria) / (Total Applicable Criteria) \u00d7 100%\n```\n\n### Level Determination\n```\nFor each level L (1 to 5):\n  If (pass rate at L \u2265 80%) AND (all lower levels \u2265 80%):\n    Repository is at level L\n```\n\n### Organization Score\n```\nOrg Level = floor(average of all repository levels)\nKey Metric = % of active repos at L3+\n```\n\n---\n\n## Priority Order for Improvement\n\n1. **Fix L1 failures first**: These block basic operation\n2. **Then L2**: Enable fast feedback loops\n3. **Aim for L3**: Production-ready target\n4. **L4+ is optimization**: Nice to have, not essential\n\n### Quick Wins by Level\n\n**L1 \u2192 L2**:\n- Add pre-commit hooks\n- Document setup commands\n- Add AGENTS.md\n\n**L2 \u2192 L3**:\n- Add integration tests\n- Set up devcontainer\n- Configure automated reviews\n\n**L3 \u2192 L4**:\n- Add complexity analysis\n- Set up flaky test detection\n- Enable security scanning",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/readiness-report/references/maturity-levels.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/sunset-boulevard",
            "content": "# Sunset Boulevard\n\nA warm and vibrant theme inspired by golden hour sunsets, perfect for energetic and creative presentations.\n\n## Color Palette\n\n- **Burnt Orange**: `#e76f51` - Primary accent color\n- **Coral**: `#f4a261` - Secondary warm accent\n- **Warm Sand**: `#e9c46a` - Highlighting and backgrounds\n- **Deep Purple**: `#264653` - Dark contrast and text\n\n## Typography\n\n- **Headers**: DejaVu Serif Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nCreative pitches, marketing presentations, lifestyle brands, event promotions, inspirational content.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/sunset-boulevard.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/tech-innovation",
            "content": "# Tech Innovation\n\nA bold and modern theme with high-contrast colors perfect for cutting-edge technology presentations.\n\n## Color Palette\n\n- **Electric Blue**: `#0066ff` - Vibrant primary accent\n- **Neon Cyan**: `#00ffff` - Bright highlight color\n- **Dark Gray**: `#1e1e1e` - Deep backgrounds\n- **White**: `#ffffff` - Clean text and contrast\n\n## Typography\n\n- **Headers**: DejaVu Sans Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nTech startups, software launches, innovation showcases, AI/ML presentations, digital transformation content.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/tech-innovation.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/arctic-frost",
            "content": "# Arctic Frost\n\nA cool and crisp winter-inspired theme that conveys clarity, precision, and professionalism.\n\n## Color Palette\n\n- **Ice Blue**: `#d4e4f7` - Light backgrounds and highlights\n- **Steel Blue**: `#4a6fa5` - Primary accent color\n- **Silver**: `#c0c0c0` - Metallic accent elements\n- **Crisp White**: `#fafafa` - Clean backgrounds and text\n\n## Typography\n\n- **Headers**: DejaVu Sans Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nHealthcare presentations, technology solutions, winter sports, clean tech, pharmaceutical content.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/arctic-frost.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/modern-minimalist",
            "content": "# Modern Minimalist\n\nA clean and contemporary theme with a sophisticated grayscale palette for maximum versatility.\n\n## Color Palette\n\n- **Charcoal**: `#36454f` - Primary dark color\n- **Slate Gray**: `#708090` - Medium gray for accents\n- **Light Gray**: `#d3d3d3` - Backgrounds and dividers\n- **White**: `#ffffff` - Text and clean backgrounds\n\n## Typography\n\n- **Headers**: DejaVu Sans Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nTech presentations, architecture portfolios, design showcases, modern business proposals, data visualization.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/modern-minimalist.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/golden-hour",
            "content": "# Golden Hour\n\nA rich and warm autumnal palette that creates an inviting and sophisticated atmosphere.\n\n## Color Palette\n\n- **Mustard Yellow**: `#f4a900` - Bold primary accent\n- **Terracotta**: `#c1666b` - Warm secondary color\n- **Warm Beige**: `#d4b896` - Neutral backgrounds\n- **Chocolate Brown**: `#4a403a` - Dark text and anchors\n\n## Typography\n\n- **Headers**: FreeSans Bold\n- **Body Text**: FreeSans\n\n## Best Used For\n\nRestaurant presentations, hospitality brands, fall campaigns, cozy lifestyle content, artisan products.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/golden-hour.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/midnight-galaxy",
            "content": "# Midnight Galaxy\n\nA dramatic and cosmic theme with deep purples and mystical tones for impactful presentations.\n\n## Color Palette\n\n- **Deep Purple**: `#2b1e3e` - Rich dark base\n- **Cosmic Blue**: `#4a4e8f` - Mystical mid-tone\n- **Lavender**: `#a490c2` - Soft accent color\n- **Silver**: `#e6e6fa` - Light highlights and text\n\n## Typography\n\n- **Headers**: FreeSans Bold\n- **Body Text**: FreeSans\n\n## Best Used For\n\nEntertainment industry, gaming presentations, nightlife venues, luxury brands, creative agencies.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/midnight-galaxy.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/forest-canopy",
            "content": "# Forest Canopy\n\nA natural and grounded theme featuring earth tones inspired by dense forest environments.\n\n## Color Palette\n\n- **Forest Green**: `#2d4a2b` - Primary dark green\n- **Sage**: `#7d8471` - Muted green accent\n- **Olive**: `#a4ac86` - Light accent color\n- **Ivory**: `#faf9f6` - Backgrounds and text\n\n## Typography\n\n- **Headers**: FreeSerif Bold\n- **Body Text**: FreeSans\n\n## Best Used For\n\nEnvironmental presentations, sustainability reports, outdoor brands, wellness content, organic products.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/forest-canopy.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/ocean-depths",
            "content": "# Ocean Depths\n\nA professional and calming maritime theme that evokes the serenity of deep ocean waters.\n\n## Color Palette\n\n- **Deep Navy**: `#1a2332` - Primary background color\n- **Teal**: `#2d8b8b` - Accent color for highlights and emphasis\n- **Seafoam**: `#a8dadc` - Secondary accent for lighter elements\n- **Cream**: `#f1faee` - Text and light backgrounds\n\n## Typography\n\n- **Headers**: DejaVu Sans Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nCorporate presentations, financial reports, professional consulting decks, trust-building content.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/ocean-depths.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/desert-rose",
            "content": "# Desert Rose\n\nA soft and sophisticated theme with dusty, muted tones perfect for elegant presentations.\n\n## Color Palette\n\n- **Dusty Rose**: `#d4a5a5` - Soft primary color\n- **Clay**: `#b87d6d` - Earthy accent\n- **Sand**: `#e8d5c4` - Warm neutral backgrounds\n- **Deep Burgundy**: `#5d2e46` - Rich dark contrast\n\n## Typography\n\n- **Headers**: FreeSans Bold\n- **Body Text**: FreeSans\n\n## Best Used For\n\nFashion presentations, beauty brands, wedding planning, interior design, boutique businesses.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/desert-rose.md",
            "inputs": [],
            "is_agentskills_format": false
          },
          {
            "name": "skills/theme-factory/themes/botanical-garden",
            "content": "# Botanical Garden\n\nA fresh and organic theme featuring vibrant garden-inspired colors for lively presentations.\n\n## Color Palette\n\n- **Fern Green**: `#4a7c59` - Rich natural green\n- **Marigold**: `#f9a620` - Bright floral accent\n- **Terracotta**: `#b7472a` - Earthy warm tone\n- **Cream**: `#f5f3ed` - Soft neutral backgrounds\n\n## Typography\n\n- **Headers**: DejaVu Serif Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nGarden centers, food presentations, farm-to-table content, botanical brands, natural products.",
            "source": "/Users/atineose/.openhands/cache/skills/public-skills/skills/theme-factory/themes/botanical-garden.md",
            "inputs": [],
            "is_agentskills_format": false
          }
        ],
        "system_message_suffix": "Your current working directory is: /Users/atineose/.openhands\nUser operating system: macOS 26.2",
        "load_user_skills": true,
        "load_public_skills": true
      },
      "system_prompt_filename": "system_prompt.j2",
      "security_policy_filename": "security_policy.j2",
      "system_prompt_kwargs": {
        "cli_mode": true,
        "llm_security_analyzer": true
      },
      "condenser": {
        "llm": {
          "model": "openai/Claude-Haiku-4.5",
          "api_key": "**********",
          "base_url": "https://api.poe.com/v1",
          "openrouter_site_url": "https://docs.all-hands.dev/",
          "openrouter_app_name": "OpenHands",
          "num_retries": 5,
          "retry_multiplier": 8.0,
          "retry_min_wait": 8,
          "retry_max_wait": 64,
          "max_message_chars": 30000,
          "temperature": 0.0,
          "top_p": 1.0,
          "max_input_tokens": 128000,
          "max_output_tokens": 16000,
          "stream": false,
          "drop_params": true,
          "modify_params": true,
          "disable_stop_word": false,
          "caching_prompt": true,
          "log_completions": false,
          "log_completions_folder": "logs/completions",
          "native_tool_calling": true,
          "reasoning_effort": "high",
          "enable_encrypted_reasoning": true,
          "prompt_cache_retention": "24h",
          "extended_thinking_budget": 200000,
          "usage_id": "condenser",
          "litellm_extra_body": {}
        },
        "max_size": 80,
        "keep_first": 2,
        "hard_context_reset_max_retries": 5,
        "hard_context_reset_context_scaling": 0.8,
        "kind": "LLMSummarizingCondenser"
      },
      "kind": "Agent"
    },
    "workspace": {
      "working_dir": "/Users/atineose/.openhands",
      "kind": "LocalWorkspace"
    },
    "persistence_dir": "/Users/atineose/.openhands/conversations/738af793554247daab6f62001054d444",
    "max_iterations": 500,
    "stuck_detection": true,
    "execution_status": "finished",
    "confirmation_policy": {
      "threshold": "HIGH",
      "confirm_unknown": true,
      "kind": "ConfirmRisky"
    },
    "security_analyzer": {
      "kind": "LLMSecurityAnalyzer"
    },
    "activated_knowledge_skills": [],
    "blocked_actions": {},
    "blocked_messages": {},
    "stats": {
      "usage_to_metrics": {
        "agent": {
          "model_name": "openai/Claude-Haiku-4.5",
          "accumulated_cost": 0.0,
          "accumulated_token_usage": {
            "model": "openai/Claude-Haiku-4.5",
            "prompt_tokens": 1884833,
            "completion_tokens": 9864,
            "cache_read_tokens": 1829076,
            "cache_write_tokens": 0,
            "reasoning_tokens": 0,
            "context_window": 128000,
            "per_turn_token": 55783,
            "response_id": ""
          },
          "costs": [],
          "response_latencies": [
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.8317220211029053,
              "response_id": "chatcmpl-4db77ad0b158ac08ef2bd455"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 2.8037350177764893,
              "response_id": "chatcmpl-37aa173894ab90debc5062ba"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.147643804550171,
              "response_id": "chatcmpl-67178c54af6f7a7eb71150c4"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.5694692134857178,
              "response_id": "chatcmpl-b3d7cd2e7794f32cc96936b9"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.350253105163574,
              "response_id": "chatcmpl-db2b5e714bb6db79b7cabb05"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 2.8783578872680664,
              "response_id": "chatcmpl-639a7937bfa26df1b2572262"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.169288158416748,
              "response_id": "chatcmpl-2fbc040ccc953b02e30cfe6a"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.3523499965667725,
              "response_id": "chatcmpl-5399bdf34db7a85b2d0330f4"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.373701810836792,
              "response_id": "chatcmpl-45390719691e92787ef38674"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 5.317270994186401,
              "response_id": "chatcmpl-4cbd84734eb85da393ebb5c7"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.4266891479492188,
              "response_id": "chatcmpl-4bc167ae220427e5ed0b4c24"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 6.668129205703735,
              "response_id": "chatcmpl-f6b9c52f5205c0b0aaa6bd64"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.0869011878967285,
              "response_id": "chatcmpl-06b2f890279afc4c0ba9f8e5"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.0593199729919434,
              "response_id": "chatcmpl-a1795d134403bbf191cf07a2"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 2.953791379928589,
              "response_id": "chatcmpl-86032e12a67608dcbce38166"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.135688066482544,
              "response_id": "chatcmpl-ff1257c838815a9ac9aef440"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.268075942993164,
              "response_id": "chatcmpl-9ff4f69a2891dad41b7858b7"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.296057939529419,
              "response_id": "chatcmpl-6a22ddf3b795a6e6e1c9aea2"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.3698108196258545,
              "response_id": "chatcmpl-eee1fb04b89f1a5411e2efac"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.494560956954956,
              "response_id": "chatcmpl-1f90433fb5a115cc3c47105d"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.3023712635040283,
              "response_id": "chatcmpl-08e1163dc7f1bed822aed5ee"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.8744471073150635,
              "response_id": "chatcmpl-6b4949897ea3ebf93489c741"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.442031145095825,
              "response_id": "chatcmpl-46ae8de88d985c1b95c9fd3d"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 6.585381269454956,
              "response_id": "chatcmpl-5176dbc18eb359b1625e32c7"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 5.813192844390869,
              "response_id": "chatcmpl-32ce69615796b80ac60959c5"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.7902560234069824,
              "response_id": "chatcmpl-5182d55fa7fa78207f23dc20"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.243700981140137,
              "response_id": "chatcmpl-27cb5aa981b4e26e8e219313"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.0232861042022705,
              "response_id": "chatcmpl-9f4f325beb83aa67b2a69e26"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.147785902023315,
              "response_id": "chatcmpl-d2a0bfed555e888dc730d552"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.343420028686523,
              "response_id": "chatcmpl-34486214d1c94d461858cd49"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.109718084335327,
              "response_id": "chatcmpl-15cd421db4791779b399b906"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.2386298179626465,
              "response_id": "chatcmpl-1c565a5f8f96d2533246d455"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 7.052227735519409,
              "response_id": "chatcmpl-2e75f61a06779458dffe8e97"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.123008966445923,
              "response_id": "chatcmpl-a98f207fc69c97206c09cf3f"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 6.425372123718262,
              "response_id": "chatcmpl-9e573209116cbefba29b54b7"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.0206849575042725,
              "response_id": "chatcmpl-9bc74b521ab1753649f0f614"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.373971939086914,
              "response_id": "chatcmpl-9abbab57295fd65df584734a"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.6348650455474854,
              "response_id": "chatcmpl-d179bac12af5f3b02ce8ee15"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.069059133529663,
              "response_id": "chatcmpl-c89c01f5fb70b72b260567a5"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.380864143371582,
              "response_id": "chatcmpl-00eb61c82af3eea0f38a6898"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.065096855163574,
              "response_id": "chatcmpl-7737436685e4d3abd882a602"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.539815902709961,
              "response_id": "chatcmpl-dc1e8c063eb014217bdfd035"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.517754077911377,
              "response_id": "chatcmpl-4147412b8c79193e046c607f"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 3.5508930683135986,
              "response_id": "chatcmpl-67d347313f325477f859c0b1"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.624580144882202,
              "response_id": "chatcmpl-b1d678540ec3ce98abc54590"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "latency": 4.890784025192261,
              "response_id": "chatcmpl-4a40fe7d0476a6d5c5819490"
            }
          ],
          "token_usages": [
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 23081,
              "completion_tokens": 149,
              "cache_read_tokens": 0,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 23230,
              "response_id": "chatcmpl-4db77ad0b158ac08ef2bd455"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 25503,
              "completion_tokens": 140,
              "cache_read_tokens": 23078,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 25643,
              "response_id": "chatcmpl-37aa173894ab90debc5062ba"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 29178,
              "completion_tokens": 175,
              "cache_read_tokens": 25498,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 29353,
              "response_id": "chatcmpl-67178c54af6f7a7eb71150c4"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 29748,
              "completion_tokens": 198,
              "cache_read_tokens": 29173,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 29946,
              "response_id": "chatcmpl-b3d7cd2e7794f32cc96936b9"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 32174,
              "completion_tokens": 213,
              "cache_read_tokens": 29743,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 32387,
              "response_id": "chatcmpl-db2b5e714bb6db79b7cabb05"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 32561,
              "completion_tokens": 166,
              "cache_read_tokens": 32169,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 32727,
              "response_id": "chatcmpl-639a7937bfa26df1b2572262"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 33084,
              "completion_tokens": 165,
              "cache_read_tokens": 32556,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 33249,
              "response_id": "chatcmpl-2fbc040ccc953b02e30cfe6a"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 33408,
              "completion_tokens": 167,
              "cache_read_tokens": 33079,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 33575,
              "response_id": "chatcmpl-5399bdf34db7a85b2d0330f4"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 33738,
              "completion_tokens": 165,
              "cache_read_tokens": 33403,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 33903,
              "response_id": "chatcmpl-45390719691e92787ef38674"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 34065,
              "completion_tokens": 516,
              "cache_read_tokens": 33733,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 34581,
              "response_id": "chatcmpl-4cbd84734eb85da393ebb5c7"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 35187,
              "completion_tokens": 91,
              "cache_read_tokens": 34060,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 35278,
              "response_id": "chatcmpl-4bc167ae220427e5ed0b4c24"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 35364,
              "completion_tokens": 497,
              "cache_read_tokens": 35182,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 35861,
              "response_id": "chatcmpl-f6b9c52f5205c0b0aaa6bd64"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 35960,
              "completion_tokens": 182,
              "cache_read_tokens": 35359,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 36142,
              "response_id": "chatcmpl-06b2f890279afc4c0ba9f8e5"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 36839,
              "completion_tokens": 91,
              "cache_read_tokens": 35955,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 36930,
              "response_id": "chatcmpl-a1795d134403bbf191cf07a2"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 37016,
              "completion_tokens": 87,
              "cache_read_tokens": 36834,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 37103,
              "response_id": "chatcmpl-86032e12a67608dcbce38166"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 37236,
              "completion_tokens": 133,
              "cache_read_tokens": 37011,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 37369,
              "response_id": "chatcmpl-ff1257c838815a9ac9aef440"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 37497,
              "completion_tokens": 181,
              "cache_read_tokens": 37231,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 37678,
              "response_id": "chatcmpl-9ff4f69a2891dad41b7858b7"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 37851,
              "completion_tokens": 176,
              "cache_read_tokens": 37492,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 38027,
              "response_id": "chatcmpl-6a22ddf3b795a6e6e1c9aea2"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 38204,
              "completion_tokens": 176,
              "cache_read_tokens": 37846,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 38380,
              "response_id": "chatcmpl-eee1fb04b89f1a5411e2efac"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 38747,
              "completion_tokens": 192,
              "cache_read_tokens": 38199,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 38939,
              "response_id": "chatcmpl-1f90433fb5a115cc3c47105d"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 39111,
              "completion_tokens": 174,
              "cache_read_tokens": 38742,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 39285,
              "response_id": "chatcmpl-08e1163dc7f1bed822aed5ee"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 39481,
              "completion_tokens": 231,
              "cache_read_tokens": 39106,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 39712,
              "response_id": "chatcmpl-6b4949897ea3ebf93489c741"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 39935,
              "completion_tokens": 209,
              "cache_read_tokens": 39476,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 40144,
              "response_id": "chatcmpl-46ae8de88d985c1b95c9fd3d"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 40269,
              "completion_tokens": 469,
              "cache_read_tokens": 39930,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 40738,
              "response_id": "chatcmpl-5176dbc18eb359b1625e32c7"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 40783,
              "completion_tokens": 258,
              "cache_read_tokens": 40264,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 41041,
              "response_id": "chatcmpl-32ce69615796b80ac60959c5"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 41379,
              "completion_tokens": 221,
              "cache_read_tokens": 40781,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 41600,
              "response_id": "chatcmpl-5182d55fa7fa78207f23dc20"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 42358,
              "completion_tokens": 186,
              "cache_read_tokens": 41374,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 42544,
              "response_id": "chatcmpl-27cb5aa981b4e26e8e219313"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 44189,
              "completion_tokens": 184,
              "cache_read_tokens": 42353,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 44373,
              "response_id": "chatcmpl-9f4f325beb83aa67b2a69e26"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 44543,
              "completion_tokens": 190,
              "cache_read_tokens": 44184,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 44733,
              "response_id": "chatcmpl-d2a0bfed555e888dc730d552"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 44954,
              "completion_tokens": 131,
              "cache_read_tokens": 44538,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 45085,
              "response_id": "chatcmpl-34486214d1c94d461858cd49"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 45406,
              "completion_tokens": 148,
              "cache_read_tokens": 44949,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 45554,
              "response_id": "chatcmpl-15cd421db4791779b399b906"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 45693,
              "completion_tokens": 145,
              "cache_read_tokens": 45401,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 45838,
              "response_id": "chatcmpl-1c565a5f8f96d2533246d455"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 46298,
              "completion_tokens": 746,
              "cache_read_tokens": 45688,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 47044,
              "response_id": "chatcmpl-2e75f61a06779458dffe8e97"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 47489,
              "completion_tokens": 91,
              "cache_read_tokens": 46293,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 47580,
              "response_id": "chatcmpl-a98f207fc69c97206c09cf3f"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 47666,
              "completion_tokens": 690,
              "cache_read_tokens": 47484,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 48356,
              "response_id": "chatcmpl-9e573209116cbefba29b54b7"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 48819,
              "completion_tokens": 91,
              "cache_read_tokens": 47661,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 48910,
              "response_id": "chatcmpl-9bc74b521ab1753649f0f614"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 48996,
              "completion_tokens": 140,
              "cache_read_tokens": 48814,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 49136,
              "response_id": "chatcmpl-9abbab57295fd65df584734a"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 49270,
              "completion_tokens": 132,
              "cache_read_tokens": 48991,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 49402,
              "response_id": "chatcmpl-d179bac12af5f3b02ce8ee15"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 49568,
              "completion_tokens": 202,
              "cache_read_tokens": 49265,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 49770,
              "response_id": "chatcmpl-c89c01f5fb70b72b260567a5"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 49950,
              "completion_tokens": 194,
              "cache_read_tokens": 49563,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 50144,
              "response_id": "chatcmpl-00eb61c82af3eea0f38a6898"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 50317,
              "completion_tokens": 212,
              "cache_read_tokens": 49945,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 50529,
              "response_id": "chatcmpl-7737436685e4d3abd882a602"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 50662,
              "completion_tokens": 162,
              "cache_read_tokens": 50312,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 50824,
              "response_id": "chatcmpl-dc1e8c063eb014217bdfd035"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 51110,
              "completion_tokens": 174,
              "cache_read_tokens": 50657,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 51284,
              "response_id": "chatcmpl-4147412b8c79193e046c607f"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 51812,
              "completion_tokens": 172,
              "cache_read_tokens": 51105,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 51984,
              "response_id": "chatcmpl-67d347313f325477f859c0b1"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 52797,
              "completion_tokens": 206,
              "cache_read_tokens": 51807,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 53003,
              "response_id": "chatcmpl-b1d678540ec3ce98abc54590"
            },
            {
              "model": "openai/Claude-Haiku-4.5",
              "prompt_tokens": 55537,
              "completion_tokens": 246,
              "cache_read_tokens": 52792,
              "cache_write_tokens": 0,
              "reasoning_tokens": 0,
              "context_window": 128000,
              "per_turn_token": 55783,
              "response_id": "chatcmpl-4a40fe7d0476a6d5c5819490"
            }
          ]
        },
        "condenser": {
          "model_name": "openai/Claude-Haiku-4.5",
          "accumulated_cost": 0.0,
          "accumulated_token_usage": {
            "model": "openai/Claude-Haiku-4.5",
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "cache_read_tokens": 0,
            "cache_write_tokens": 0,
            "reasoning_tokens": 0,
            "context_window": 0,
            "per_turn_token": 0,
            "response_id": ""
          },
          "costs": [],
          "response_latencies": [],
          "token_usages": []
        }
      }
    },
    "secret_registry": {
      "secret_sources": {}
    }
  },
  "model": "openai/Claude-Haiku-4.5"
}